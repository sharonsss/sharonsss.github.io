<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Elasticsearch + Kibana 安装记录</title>
    <link href="/2020/04/05/elasticsearch%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95/"/>
    <url>/2020/04/05/elasticsearch%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<p>公司今年的项目要把原来的数据迁移到Elasticsearch数据库中，通过技术负责人的介绍，我才知道了ES+kibana这个组合，开源，可以基于ES数据直接在Kibana上进行数据查询和图表分析。<a id="more"></a> 想我们之前还苦哈哈的自己写Echarts做数据图表，虽然实现了我们最初的需求，但是和采用Kibana比起来，还是占用了不少的时间和精力。</p><p>这几天在本地搭建了ES+Kibana，在此记录一下。</p><h1 id="Elasticsearch-安装"><a href="#Elasticsearch-安装" class="headerlink" title="Elasticsearch 安装"></a>Elasticsearch 安装</h1><h2 id="下载与安装"><a href="#下载与安装" class="headerlink" title="下载与安装"></a>下载与安装</h2><p>Elasticsearch的安装方式相对来说比较简单。<code>brew</code>的安装方式对我来说太慢，于是直接在官网上下载的安装包（公司网太慢，下个安装包还花了一天时间）。</p><ul><li><p>下载地址：<a href="https://www.elastic.co/downloads/elasticsearch" target="_blank" rel="noopener">https://www.elastic.co/downloads/elasticsearch</a></p></li><li><p>安装版本：7.6.2 （与Kibana的版本要一致）</p></li></ul><p>下载完成之后，放到<code>/usr/local/Cellar/</code>路径下，解压。</p><p>进入 bin 目录启动 ES 并在运行：</p><pre><code>$ ./elasticsearch$ ./elasticsearch -d (后台运行)</code></pre><p>curl 测试是否正常运行（或者在浏览器中打开）：</p><pre><code>$ curl 127.0.0.1:9200</code></pre><p>此时出现：</p><pre><code>{  &quot;name&quot; : &quot;mvQoSGm&quot;,  &quot;cluster_name&quot; : &quot;elasticsearch&quot;,  &quot;cluster_uuid&quot; : &quot;4vUSt2_AQFSj5LZDVgR74g&quot;,  &quot;version&quot; : {    &quot;number&quot; : &quot;7.6.2&quot;,    &quot;build_flavor&quot; : &quot;default&quot;,    &quot;build_type&quot; : &quot;tar&quot;,    &quot;build_hash&quot; : &quot;04711c2&quot;,    &quot;build_date&quot; : &quot;2020-04-02T13:34:09.098244Z&quot;,    &quot;build_snapshot&quot; : false,    &quot;lucene_version&quot; : &quot;7.4.0&quot;,    &quot;minimum_wire_compatibility_version&quot; : &quot;6.6.0&quot;,    &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0&quot;  },  &quot;tagline&quot; : &quot;You Know, for Search&quot;</code></pre><p>表示安装成功。</p><p>初步安装之后，我并没有做其他的设置，还有一些插件因为下载路径实在太慢，准备后面再慢慢安装。</p><h2 id="查看ES集群的简单命令"><a href="#查看ES集群的简单命令" class="headerlink" title="查看ES集群的简单命令"></a>查看ES集群的简单命令</h2><h3 id="1-查看集群的健康状态"><a href="#1-查看集群的健康状态" class="headerlink" title="1. 查看集群的健康状态"></a>1. 查看集群的健康状态</h3><pre><code>http://127.0.0.1:9200/_cat/health?v</code></pre><p>URL中_cat表示查看信息，health表明返回的信息为集群健康信息，?v表示返回的信息加上头信息，跟返回JSON信息加上?。</p><ul><li><p>集群的状态（status）：red红表示集群不可用，有故障。yellow黄表示集群不可靠但可用，一般单节点时就是此状态。green正常状态，表示集群一切正常。</p></li><li><p>节点数（node.total）：节点数，这里是2，表示该集群有两个节点。</p></li><li><p>数据节点数（node.data）：存储数据的节点数，这里是2。数据节点在Elasticsearch概念介绍有。</p></li><li><p>分片数（shards）：这是12，表示我们把数据分成多少块存储。</p></li><li><p>主分片数（pri）：primary shards，这里是6，实际上是分片数的两倍，因为有一个副本，如果有两个副本，这里的数量应该是分片数的三倍，这个会跟后面的索引分片数对应起来，这里只是个总数。</p></li><li><p>激活的分片百分比（active_shards_percent）：这里可以理解为加载的数据分片数，只有加载所有的分片数，集群才算正常启动，在启动的过程中，如果我们不断刷新这个页面，我们会发现这个百分比会不断加大。</p></li></ul><p><img src="/img/1.png" srcset="/img/loading.gif" alt="1"></p><h3 id="2-查看集群的索引数"><a href="#2-查看集群的索引数" class="headerlink" title="2. 查看集群的索引数"></a>2. 查看集群的索引数</h3><pre><code>http://127.0.0.1:9200/_cat/indices?v</code></pre><ul><li><p>索引健康（health），green为正常，yellow表示索引不可靠（单节点），red索引不可用。与集群健康状态一致。</p></li><li><p>状态（status），表明索引是否打开。</p></li><li><p>索引名称（index），这里有.kibana和school。</p></li><li><p>uuid，索引内部随机分配的名称，表示唯一标识这个索引。</p></li><li><p>主分片（pri），.kibana为1，school为5，加起来主分片数为6，这个就是集群的主分片数。</p></li><li><p>文档数（docs.count），school在之前的演示添加了两条记录，所以这里的文档数为2。</p></li><li><p>已删除文档数（docs.deleted），这里统计了被删除文档的数量。</p></li><li><p>索引存储的总容量（store.size），这里school索引的总容量为6.4kb，是主分片总容量的两倍，因为存在一个副本。</p></li><li><p>主分片的总容量（pri.store.size），这里school的主分片容量是7kb，是索引总容量的一半。</p></li></ul><p><img src="/img/2.png" srcset="/img/loading.gif" alt="2"></p><h3 id="3-查看集群所在磁盘的分配状况"><a href="#3-查看集群所在磁盘的分配状况" class="headerlink" title="3. 查看集群所在磁盘的分配状况"></a>3. 查看集群所在磁盘的分配状况</h3><pre><code>http://127.0.0.1:9200/_cat/allocation?v</code></pre><p>返回集群中的各节点所在磁盘的磁盘状况。</p><h3 id="4-查看集群的节点"><a href="#4-查看集群的节点" class="headerlink" title="4. 查看集群的节点"></a>4. 查看集群的节点</h3><pre><code>http://127.0.0.1:9200/_cat/nodes?v</code></pre><p>通过该连接返回了集群中各节点的情况。这些信息中比较重要的是master列，带*星号表明该节点是主节点。带-表明该节点是从节点。</p><pre><code>ip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name127.0.0.1 19 99 6 2.86 mdi * ruan-node-1127.0.0.1 13 99 6 2.86 mdi - ruan-node-2</code></pre><h3 id="5-查看集群的其它信息"><a href="#5-查看集群的其它信息" class="headerlink" title="5. 查看集群的其它信息"></a>5. 查看集群的其它信息</h3><pre><code>http://127.0.0.1:9200/_cat/</code></pre><p>获得查看集群信息的目录。</p><h3 id="6-全词搜索"><a href="#6-全词搜索" class="headerlink" title="6. 全词搜索"></a>6. 全词搜索</h3><pre><code>http://127.0.0.1:9200/indexName/_search?pretty=true</code></pre><p><code>pretty=true</code> 表示格式化输出。</p><h3 id="7-精准搜索"><a href="#7-精准搜索" class="headerlink" title="7. 精准搜索"></a>7. 精准搜索</h3><pre><code>http://127.0.0.1:9200/indexName/_search?q=123&amp;pretty=true</code></pre><p>表示搜索“123”。</p><h3 id="8-模糊搜索"><a href="#8-模糊搜索" class="headerlink" title="8. 模糊搜索"></a>8. 模糊搜索</h3><pre><code>http://127.0.0.1:9200/indexName/_search?q=*123*&amp;pretty=true</code></pre><p>模糊搜索“123”。</p><h1 id="Kibana-安装"><a href="#Kibana-安装" class="headerlink" title="Kibana 安装"></a>Kibana 安装</h1><h2 id="下载与安装-1"><a href="#下载与安装-1" class="headerlink" title="下载与安装"></a>下载与安装</h2><p>Kibana安装时要注意与ES是同一个版本，ES我的版本是7.6.2，因此Kibana也下载的7.6.2版本的安装包。</p><ul><li>下载地址同官网</li><li>版本：7.6.2</li></ul><p>下载完成后，同样解压到<code>/usr/local/Cellar/</code>路径下。</p><p>进入kibana中的bin目录中，启动：</p><pre><code>$ ./kibana</code></pre><p>Kibana默认端口号<em>5601</em>， 启动成功后，到浏览器输入<code>hocalhost:5601</code>，就能进入Kibana页面了。</p><p>Kibana 7.x版本界面终于做的好看了一些。公司目前用的是5.x版本，界面简单粗暴，看起来总有些怪怪的。</p><p><img src="/img/kibana_cut.png" srcset="/img/loading.gif" alt="3"></p><p><strong>问题：</strong></p><p>在公司安装时，localhost:5601地址可以直接访问Kibana，但是回到家之后再次访问却提示localhost:5601错误，无法访问了，ES也只能通过127.0.0.1:9200才能访问，localhost：9200显示无法连接。</p><p>后来在<code>kibana.yml</code>配置文件里把localhost改成127.0.0.1之后，才能通过127.0.0.1:5601访问，不知道是不是我改动了一些配置？？</p><p>之后再调整一下看看。</p><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>首先在<code>Management</code>中配置<code>Index Patterns</code>，将想要分析的Index加入进来。</p><p>在<code>Dev Tools</code>里写命令获取数据：</p><pre><code>GET /data_index/_search{  &quot;query&quot;: {    &quot;match_all&quot;: {}  }}</code></pre><p>上面是最简单的获取，Kibana还有其他的Lucene查询语法，可以查询更多的ES数据，按条件查询、搜索等，待实际应用中慢慢学习。</p><p>今天先初步记录安装与使用的信息，以免过后忘记。</p><hr><p><strong>参考来源：</strong></p><ul><li><em><a href="https://blog.csdn.net/genghaihua/article/details/81479619" target="_blank" rel="noopener">ES查看集群信息命令</a></em></li><li><em><a href="https://blog.csdn.net/a544258023/article/details/89709046?depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-2&utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-2" target="_blank" rel="noopener">ElasticSearch常用查询命令</a></em></li></ul>]]></content>
    
    
    <categories>
      
      <category>ELK</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kibana</tag>
      
      <tag>Elasticsearch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Elasticdump 踩坑记录</title>
    <link href="/2020/04/02/elasticdump%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"/>
    <url>/2020/04/02/elasticdump%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<blockquote><p>感觉这几天是自己的智商低谷。😭</p></blockquote><h1 id="Elasticdump-安装"><a href="#Elasticdump-安装" class="headerlink" title="Elasticdump 安装"></a>Elasticdump 安装</h1><p>为了解决远程ES数据库导入到本地ES的问题，今天在网上查了一天资料。了解到ELK中的Logstash可以实现这个需求，同时Logstash似乎还隐藏着更多其他炫酷功能，包括我后面可能要用到的web接口。<a id="more"></a> 感觉到这是一个稍微大点的功能，最终决定后面专门腾出时间来研究。</p><p>于是就找到了另外一个非常轻量级的ElasticSearch插件————Elasticdump，专门解决ES数据导入导出的问题。“dump”也是个非常形象的词了，有些简单粗暴，就跟它的实现一样。</p><p>安装Elasticdump很简单，mac上直接 <code>npm install elasticdump</code> 就好了。也可以全剧安装 <code>npm install elasticdump -g</code> 。</p><h1 id="将远程-ES-数据导出到本地-JSON-文件"><a href="#将远程-ES-数据导出到本地-JSON-文件" class="headerlink" title="将远程 ES 数据导出到本地 JSON 文件"></a>将远程 ES 数据导出到本地 JSON 文件</h1><p>这里演示的是我把远程ES上的数据导出到本地的JSON文件。最初的想法是，把远程ES数据导到本地文件，再把文件导入本地的ES。此时，我并没有想到远程ES和本地ES可以直接导入导出，脑子卡在了本地文件里。😓</p><p>实际output部分为本地文件路径，具体如下：</p><pre><code># 格式：$ elasticdump --input {protocol}://{host}:{port}/{index} --output ./test_index.json# 例子：将ES中的test_index 中的索引导出# 导出当前索引的mapping结构$ elasticdump --input http://192.168.56.104:9200/test_index \--output ./test_index_mapping.json --type=mapping# 导出当前索引下的所有真实数据$ elasticdump --input http://192.168.56.104:9200/test_index \--output ./test_index.json --type=data</code></pre><h1 id="将远程的-ES-数据导出到本地-ES"><a href="#将远程的-ES-数据导出到本地-ES" class="headerlink" title="将远程的 ES 数据导出到本地 ES"></a>将远程的 ES 数据导出到本地 ES</h1><p>本地JSON导出之后，终于想到elasticdump明明可以连接远程和本地ES。。。</p><h2 id="无账号密码的情况下导出"><a href="#无账号密码的情况下导出" class="headerlink" title="无账号密码的情况下导出"></a>无账号密码的情况下导出</h2><p>如果远程和本地的ES都不需要账号密码访问权限，相对来说就比较容易，直接遵循下面的格式就可以。</p><p>官方提供的数据迁移示例：</p><pre><code># 拷贝analyzer分词elasticdump \  --input=http://production.es.com:9200/my_index \  --output=http://staging.es.com:9200/my_index \  --type=analyzer</code></pre><pre><code># 拷贝映射elasticdump \  --input=http://production.es.com:9200/my_index \  --output=http://staging.es.com:9200/my_index \  --type=mapping</code></pre><pre><code># 拷贝数据elasticdump \  --input=http://production.es.com:9200/my_index \  --output=http://staging.es.com:9200/my_index \  --type=data</code></pre><h2 id="设置账号密码登录导出"><a href="#设置账号密码登录导出" class="headerlink" title="设置账号密码登录导出"></a>设置账号密码登录导出</h2><p><strong>据说 elasticdump 提供给了–httpAuthFile 参数来做认证</strong></p><pre><code>--httpAuthFile      When using http auth provide credentials in ini file in form                    `user=&lt;username&gt;                    password=&lt;password&gt;`</code></pre><p>只需要写一个ini文件 ，文件中写入用户名和密码就可以了，不过这个方法我还没有试。</p><p>另外一个好的方法是，<strong>在–input参数和–output参数的的url中添加账号密码</strong>。</p><p>例如：</p><pre><code>$ elasticdump --input http://username:passowrd@production.es.com:9200/my_index \--output http://username:password@staging.es.com:9200/my_index \--type=data</code></pre><p>导出mapping</p><pre><code>$ elasticdump --input http://username:password@host:9200/data_index \--output ./test_index.json --type=mapping</code></pre><p>导出所有data</p><pre><code>$ elasticdump --input http://username:password@host:9200/data_index \--output ./test_index_data.json --type=data</code></pre><h2 id="远程-ES-需要账号密码，本地不需要"><a href="#远程-ES-需要账号密码，本地不需要" class="headerlink" title="远程 ES 需要账号密码，本地不需要"></a>远程 ES 需要账号密码，本地不需要</h2><p><strong>上面看起来行云流水一般就能搞定，事实上，对小白来说，好大的坑啊。。。</strong></p><p>折腾完上面的远程ES导出到本地JSON之外，突然发现可以直接从远程ES导入本地ES，为什么我还要拐个弯导出个本地文件，服了我自己的智商。。。</p><p><img src="/img/zhishang1.jpg" srcset="/img/loading.gif" alt="智商"></p><p>由于本地ES没有任何配置，于是我按照示例，最初想到了这样：</p><pre><code>$ elasticdump --input http://username:password@0.0.0.0:9200/data_index \--output http://localhost:9200/data_index --type=mapping</code></pre><p>报错：</p><pre><code>Error Emitted =&gt; {&quot;root_cause&quot;:[{&quot;type&quot;:&quot;mapper_parsing_exception&quot;,&quot;reason&quot;:&quot;Root mapping definition has unsupported parameters:  [kis_data_index_type : {properties={eng_exam_res={type=keyword}, item_state={type=keyword}, first_level={type=text}, chin_exam={analyzer=ik_max_word, type=text}, chinese_item={analyzer=ik_max_word, type=text}, xremark={type=keyword}, eng_synonym={type=keyword}, eng_exam={type=text}, contributor={type=text}, third_level={type=text}, chin_exam_res={type=keyword}, id={type=long}, remark_str={type=keyword}, chin_define_res={type=keyword}, chin_synonym={type=text}, eng_abbr={type=text}, contributor ={type=text, fields={keyword={ignore_above=256, type=keyword}}}, query={properties={match_all={type=object}}}, source_type={type=keyword}, english_item={analyzer=english, type=text}, second_level={type=text}, eng_define_res={type=keyword}, eng_define={type=text}, picture_res={type=keyword}, chin_abbr={type=text}, chin_define={type=text}}}]&quot;}],&quot;type&quot;:&quot;mapper_parsing_exception&quot;,&quot;reason&quot;:&quot;Root mapping definition has unsupported parameters:  [kis_data_index_type : {properties={eng_exam_res={type=keyword}, item_state={type=keyword}, first_level={type=text}, chin_exam={analyzer=ik_max_word, type=text}, chinese_item={analyzer=ik_max_word, type=text}, xremark={type=keyword}, eng_synonym={type=keyword}, eng_exam={type=text}, contributor={type=text}, third_level={type=text}, chin_exam_res={type=keyword}, id={type=long}, remark_str={type=keyword}, chin_define_res={type=keyword}, chin_synonym={type=text}, eng_abbr={type=text}, contributor ={type=text, fields={keyword={ignore_above=256, type=keyword}}}, query={properties={match_all={type=object}}}, source_type={type=keyword}, english_item={analyzer=english, type=text}, second_level={type=text}, eng_define_res={type=keyword}, eng_define={type=text}, picture_res={type=keyword}, chin_abbr={type=text}, chin_define={type=text}}}]&quot;}Error Emitted =&gt; {&quot;root_cause&quot;:[{&quot;type&quot;:&quot;mapper_parsing_exception&quot;,&quot;reason&quot;:&quot;Root mapping definition has unsupported parameters:  [kis_data_index_type : {properties={eng_exam_res={type=keyword}, item_state={type=keyword}, first_level={type=text}, chin_exam={analyzer=ik_max_word, type=text}, chinese_item={analyzer=ik_max_word, type=text}, xremark={type=keyword}, eng_synonym={type=keyword}, eng_exam={type=text}, contributor={type=text}, third_level={type=text}, chin_exam_res={type=keyword}, id={type=long}, remark_str={type=keyword}, chin_define_res={type=keyword}, chin_synonym={type=text}, eng_abbr={type=text}, contributor ={type=text, fields={keyword={ignore_above=256, type=keyword}}}, query={properties={match_all={type=object}}}, source_type={type=keyword}, english_item={analyzer=english, type=text}, second_level={type=text}, eng_define_res={type=keyword}, eng_define={type=text}, picture_res={type=keyword}, chin_abbr={type=text}, chin_define={type=text}}}]&quot;}],&quot;type&quot;:&quot;mapper_parsing_exception&quot;,&quot;reason&quot;:&quot;Root mapping definition has unsupported parameters:  [kis_data_index_type : {properties={eng_exam_res={type=keyword}, item_state={type=keyword}, first_level={type=text}, chin_exam={analyzer=ik_max_word, type=text}, chinese_item={analyzer=ik_max_word, type=text}, xremark={type=keyword}, eng_synonym={type=keyword}, eng_exam={type=text}, contributor={type=text}, third_level={type=text}, chin_exam_res={type=keyword}, id={type=long}, remark_str={type=keyword}, chin_define_res={type=keyword}, chin_synonym={type=text}, eng_abbr={type=text}, contributor ={type=text, fields={keyword={ignore_above=256, type=keyword}}}, query={properties={match_all={type=object}}}, source_type={type=keyword}, english_item={analyzer=english, type=text}, second_level={type=text}, eng_define_res={type=keyword}, eng_define={type=text}, picture_res={type=keyword}, chin_abbr={type=text}, chin_define={type=text}}}]&quot;}</code></pre><p>应该是不能直接用localhost。</p><p>于是我又试了这样：</p><pre><code>$ elasticdump --input http://username:password@0.0.0.0:9200/kis_data_index \--output http://127.0.0.1:9200/data_index --type=mapping</code></pre><p>本机地址，没错吧？</p><p>依然报同样的错误。</p><p>于是，我寻思着是不是应该用电脑无线的IP？(我还加了公司无线网的账号密码。。)</p><pre><code>$ elasticdump --input http://username:password@0.0.0.0:9200/data_index \--output http://OA:password@10.9.1.000:9200/data_index --type=mapping</code></pre><p>这次报错是连不上：</p><pre><code>Thu, 02 Apr 2020 08:01:54 GMT | starting dumpThu, 02 Apr 2020 08:01:54 GMT | got 1 objects from source elasticsearch (offset: 0)Thu, 02 Apr 2020 08:02:14 GMT | Error Emitted =&gt; connect ECONNREFUSED 0.0.0.0:9200Thu, 02 Apr 2020 08:02:14 GMT | Error Emitted =&gt; connect ECONNREFUSED 0.0.0.0:9200Thu, 02 Apr 2020 08:02:14 GMT | Total Writes: 0Thu, 02 Apr 2020 08:02:14 GMT | dump ended with error (get phase) =&gt; Error: connect ECONNREFUSED 0.0.0.0:9200:9200</code></pre><p>把账号密码去了，还是提示连不上。</p><p>这时候我才看到指令最后的 –type=mapping。</p><p>不会是这个指令多余了吧？？</p><p>删掉之后，果然通了。。</p><pre><code>$ elasticdump --input http://username:password@0.0.0.0:9200/data_index \--output http://127.0.0.1:9200/data_index</code></pre><p><strong>妈蛋!</strong><br><strong>被自己气吐血！！</strong></p><pre><code>Thu, 02 Apr 2020 08:24:37 GMT | starting dumpThu, 02 Apr 2020 08:24:37 GMT | got 100 objects from source elasticsearch (offset: 0)Thu, 02 Apr 2020 08:24:38 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:38 GMT | got 100 objects from source elasticsearch (offset: 100)Thu, 02 Apr 2020 08:24:38 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:38 GMT | got 100 objects from source elasticsearch (offset: 200)Thu, 02 Apr 2020 08:24:38 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:38 GMT | got 100 objects from source elasticsearch (offset: 300)Thu, 02 Apr 2020 08:24:38 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:38 GMT | got 100 objects from source elasticsearch (offset: 400)Thu, 02 Apr 2020 08:24:38 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:38 GMT | got 100 objects from source elasticsearch (offset: 500)Thu, 02 Apr 2020 08:24:38 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:42 GMT | got 100 objects from source elasticsearch (offset: 600)Thu, 02 Apr 2020 08:24:42 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:42 GMT | got 100 objects from source elasticsearch (offset: 700)Thu, 02 Apr 2020 08:24:43 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:43 GMT | got 100 objects from source elasticsearch (offset: 800)Thu, 02 Apr 2020 08:24:43 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:43 GMT | got 100 objects from source elasticsearch (offset: 900)Thu, 02 Apr 2020 08:24:43 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:43 GMT | got 100 objects from source elasticsearch (offset: 1000)Thu, 02 Apr 2020 08:24:43 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:48 GMT | got 100 objects from source elasticsearch (offset: 1100)Thu, 02 Apr 2020 08:24:48 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:48 GMT | got 100 objects from source elasticsearch (offset: 1200)Thu, 02 Apr 2020 08:24:48 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:48 GMT | got 100 objects from source elasticsearch (offset: 1300)Thu, 02 Apr 2020 08:24:48 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:48 GMT | got 100 objects from source elasticsearch (offset: 1400)Thu, 02 Apr 2020 08:24:48 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:48 GMT | got 100 objects from source elasticsearch (offset: 1500)Thu, 02 Apr 2020 08:24:48 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:52 GMT | got 100 objects from source elasticsearch (offset: 1600)Thu, 02 Apr 2020 08:24:52 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:53 GMT | got 100 objects from source elasticsearch (offset: 1700)Thu, 02 Apr 2020 08:24:53 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:53 GMT | got 100 objects from source elasticsearch (offset: 1800)Thu, 02 Apr 2020 08:24:53 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:53 GMT | got 100 objects from source elasticsearch (offset: 1900)Thu, 02 Apr 2020 08:24:53 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:53 GMT | got 100 objects from source elasticsearch (offset: 2000)Thu, 02 Apr 2020 08:24:53 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:08 GMT | got 100 objects from source elasticsearch (offset: 2100)Thu, 02 Apr 2020 08:25:08 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:08 GMT | got 100 objects from source elasticsearch (offset: 2200)Thu, 02 Apr 2020 08:25:08 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:08 GMT | got 100 objects from source elasticsearch (offset: 2300)Thu, 02 Apr 2020 08:25:08 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:08 GMT | got 100 objects from source elasticsearch (offset: 2400)Thu, 02 Apr 2020 08:25:08 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:08 GMT | got 100 objects from source elasticsearch (offset: 2500)Thu, 02 Apr 2020 08:25:08 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:08 GMT | got 100 objects from source elasticsearch (offset: 2600)Thu, 02 Apr 2020 08:25:08 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:13 GMT | got 100 objects from source elasticsearch (offset: 2700)Thu, 02 Apr 2020 08:25:13 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:13 GMT | got 100 objects from source elasticsearch (offset: 2800)Thu, 02 Apr 2020 08:25:13 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:13 GMT | got 100 objects from source elasticsearch (offset: 2900)Thu, 02 Apr 2020 08:25:13 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:13 GMT | got 100 objects from source elasticsearch (offset: 3000)Thu, 02 Apr 2020 08:25:13 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:13 GMT | got 100 objects from source elasticsearch (offset: 3100)Thu, 02 Apr 2020 08:25:13 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:18 GMT | got 100 objects from source elasticsearch (offset: 3200)Thu, 02 Apr 2020 08:25:18 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:18 GMT | got 100 objects from source elasticsearch (offset: 3300)Thu, 02 Apr 2020 08:25:18 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:18 GMT | got 100 objects from source elasticsearch (offset: 3400)Thu, 02 Apr 2020 08:25:18 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:18 GMT | got 100 objects from source elasticsearch (offset: 3500)Thu, 02 Apr 2020 08:25:18 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:18 GMT | got 100 objects from source elasticsearch (offset: 3600)Thu, 02 Apr 2020 08:25:18 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:23 GMT | got 35 objects from source elasticsearch (offset: 3700)Thu, 02 Apr 2020 08:25:23 GMT | sent 35 objects to destination elasticsearch, wrote 35Thu, 02 Apr 2020 08:25:23 GMT | got 0 objects from source elasticsearch (offset: 3735)Thu, 02 Apr 2020 08:25:23 GMT | Total Writes: 3735Thu, 02 Apr 2020 08:25:23 GMT | dump complete</code></pre><p>不过，我在网上研究的时候，看到示例中都有指定–type=XXX，mapping和data要分别指定。后边需要验证一下不指定–type的情况下，导入到本地ES的文件是不是同时包含了mapping和所有data数据（从导入的记录上看，确实完整导入了3735条数据）。</p><hr><p><strong>2020-04-03 补充：</strong></p><p>后来想到，–type无法访问可能是因为index指定的问题，后边遇到搜索查询数据的时候，再研究一下。</p>]]></content>
    
    
    <categories>
      
      <category>ELK</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Elasticsearch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>知识点（一）：MVVM模型</title>
    <link href="/2020/03/23/%E7%9F%A5%E8%AF%86%E7%82%B9%E4%B8%80/"/>
    <url>/2020/03/23/%E7%9F%A5%E8%AF%86%E7%82%B9%E4%B8%80/</url>
    
    <content type="html"><![CDATA[<p>在学习Vue的过程中，最先遇到的就是MVVM、耦合、解耦的概念，在这里用“知识点”的分类总结一下。</p><p>知识点的帖子应该会不断增加，积少成多做成一个系列，慢慢充实起来。<a id="more"></a></p><hr><h2 id="MVVM模型"><a href="#MVVM模型" class="headerlink" title="MVVM模型"></a>MVVM模型</h2><p>MVVM是Model-View-ViewModel的缩写，一种前端开发的模型。主要思想是，在前端页面中，把Model用纯JavaScript对象表示，View负责显示，两者做到了最大程度的分离。</p><p>在MVVM架构下，View和Model之间没有直接的联系，而是通过ViewModel来交互，View数据的变化会同步到Model中，Model数据的变化也会立即反应到View上。</p><p><img src="/img/mvvm2.png" srcset="/img/loading.gif" alt="mvvm"></p><br><p>一个MVVM框架和传统JS、jQuery操作DOM的区别是什么？</p><h3 id="传统-JS-操作DOM"><a href="#传统-JS-操作DOM" class="headerlink" title="传统 JS 操作DOM"></a>传统 JS 操作DOM</h3><p>传统的JS直接写代码逻辑去操作DOM，原生JS：</p><pre><code class="html">&lt;!-- HTML --&gt;&lt;span id=&quot;name&quot;&gt;&lt;/span&gt;</code></pre><pre><code class="js">var dom = document.getElementById(&#39;name&#39;);dom.innerHTML = &#39;Sansan&#39;;dom.style.color = &#39;red&#39;</code></pre><h3 id="jQuery-修改-DOM"><a href="#jQuery-修改-DOM" class="headerlink" title="jQuery 修改 DOM"></a>jQuery 修改 DOM</h3><pre><code class="html">&lt;!-- HTML --&gt;&lt;span id=&quot;name&quot;&gt;&lt;/span&gt;</code></pre><p>用 jQuery 修改 DOM：</p><pre><code class="js">$(&#39;#name&#39;).text(&quot;Sansan&quot;).css(&quot;color&quot;, &quot;red&quot;);</code></pre><p>jQuery中数据处理的逻辑和视图混合在一起，并未分离。</p><h3 id="MVVM-修改-DOM"><a href="#MVVM-修改-DOM" class="headerlink" title="MVVM 修改 DOM"></a>MVVM 修改 DOM</h3><p>只需要关注数据结构，由 ViewModel 进行双向绑定数据操作：</p><pre><code class="html">&lt;!-- HTML --&gt;&lt;div id=&quot;app&quot;&gt;    &lt;input v-model=&quot;name&quot; /&gt;    &lt;span&gt;姓名:{{name}}&lt;/span&gt;    &lt;span&gt;年龄:{{age}}&lt;/span&gt;&lt;/div&gt;</code></pre><p>Vue.js</p><pre><code class="js">var app = new Vue({    el: &#39;#app&#39;,    data: {        name: &#39;Sansan&#39;,        age: 20    }})</code></pre><p>Vue.js 将数据视图分离，以数据驱动视图，只关心数据变化，DOM操作被封装。</p><h2 id="耦合与解耦"><a href="#耦合与解耦" class="headerlink" title="耦合与解耦"></a>耦合与解耦</h2><h3 id="耦合"><a href="#耦合" class="headerlink" title="耦合"></a>耦合</h3><p>软件工程中，对象之间的耦合度就是对象之间的依赖性。对象之间耦合越高，维护成本越高，因此对象的设计应该使类和构件之间的耦合最小。耦合性用来衡量程序结构中各个模块之间的相互关联，同时取决于各个模块之间接口的复杂程度、调用模块的方式是什么，以及哪些信息通过接口。</p><h3 id="解耦"><a href="#解耦" class="headerlink" title="解耦"></a>解耦</h3><p>解耦即尽可能减少代码之间的耦合，数据、业务和视图之间尽可能的降低耦合。</p><p>原则就是A功能的代码不要写在B的功能代码中，如果两者之间需要交互，可以通过接口，通过消息，甚至可以引入框架，但总之就是不要直接交叉写。</p><p>在Vue中，解耦即将<strong>视图</strong>与<strong>数据</strong>分成两部分，即<strong>视图代码</strong>与<strong>业务逻辑</strong>的解耦。</p><hr><p><strong>参考来源：</strong></p><ul><li><em><a href="https://www.liaoxuefeng.com/wiki/1022910821149312/1108898947791072" target="_blank" rel="noopener">廖雪峰的官方网站</a></em></li><li><em><a href="https://blog.csdn.net/zhanghuali0210/article/details/82287544?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">vue考点 —— MVVM</a></em></li><li><em><a href="https://blog.csdn.net/u012551928/article/details/99545791" target="_blank" rel="noopener">MVVM模型</a></em></li><li><em><a href="https://blog.csdn.net/shenwansan_gz/article/details/82284957" target="_blank" rel="noopener">什么是耦合、解耦</a></em></li></ul>]]></content>
    
    
    <categories>
      
      <category>前端开发</category>
      
    </categories>
    
    
    <tags>
      
      <tag>知识点</tag>
      
      <tag>Vue.js</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>拥抱VS Code，抛弃Atom</title>
    <link href="/2020/03/20/vscode/"/>
    <url>/2020/03/20/vscode/</url>
    
    <content type="html"><![CDATA[<blockquote><p>没捣鼓过几个代码编辑器，都不好意思说自己写过代码。</p></blockquote><p>留学的时候，因为开源和颜值，爱上了Atom，期间不管它多少次龟速加载我都毫无怨言，teletype好用，暗黑主题真香。<a id="more"></a> 至于Sublime Text，因为当初觉得界面太丑，用了一次就放弃了。</p><p>可是，前几天看到VS Code、Sublime和Atom的趋势图，VS Code的势头在这两年增长很迅猛。经过两年的更新之后，VS Code的功能已经非常健全，加上速度快不卡顿，再加上还能下载Atom的主题插件，于是我就叛逃到VS Code，卸载了Atom 🙈。</p><p>经过一番折腾，记录下目前觉得实用的插件：</p><h2 id="One-Dark-Pro主题"><a href="#One-Dark-Pro主题" class="headerlink" title="One Dark Pro主题"></a>One Dark Pro主题</h2><p><img src="/img/one_dark_pro.jpg" srcset="/img/loading.gif" alt="主题"></p><p>Atom里我最爱的主题，留学期间的作业都是依靠这简洁而又不做作的主题，给我了无数次爬起来修复bug的力量。暗黑主题，配色很舒服，我个人非常喜欢。</p><p>One Dark Pro这个主题的配色，相比原版要稍微鲜艳一些，看了一下配置文件里的颜色代码一致，但呈现出来的效果却有一些差别。自己捣鼓了几版配色觉得还是不太满意，暂且先用默认的了。部分类别配色的设置红色偏多，稍稍做了一些修改，显得整体的红配绿不那么突兀。</p><h2 id="Color-Highlight"><a href="#Color-Highlight" class="headerlink" title="Color Highlight"></a>Color Highlight</h2><p>这个插件可以把颜色代码显示出对应的颜色，不需要依靠页面预览才能看到效果，调试CSS配色的时候更加方便，节省时间。</p><h2 id="Live-Server"><a href="#Live-Server" class="headerlink" title="Live Server"></a>Live Server</h2><img src="/img/live.jpg" srcset="/img/loading.gif" width="30%"><p>如果是前端开发，这个插件就很有用了，可以在浏览器实时显示HTML页面。最近在学习Vue，简单的例子都可以在网页里localhost实时预览，不要太方便。</p><h2 id="Vetur"><a href="#Vetur" class="headerlink" title="Vetur"></a>Vetur</h2><p>如果学习Vue，这个插件就是必备了。另外还需要一些其他的配置，后面Vue学习的部分再来细说。</p><p>另外还有代码格式美化、minimap（自带）、terminal（自带）都是编辑器里很好的助手。必需的插件配置好之后，就可以愉快的coding了。另外，VS Code也支持Python相关的环境配置，比如Jupyter Notebook之类的，我暂时还没尝试。</p><p>初步体验下来，VS Code确实像You大说的一样，真香。</p>]]></content>
    
    
    <categories>
      
      <category>前端开发</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2020年的一些计划</title>
    <link href="/2020/01/08/2020%E5%B9%B4%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%A1%E5%88%92/"/>
    <url>/2020/01/08/2020%E5%B9%B4%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%A1%E5%88%92/</url>
    
    <content type="html"><![CDATA[<p>经过一天的时间搭建Hexo，我的个人博客地址有个了雏形，目前还在找背景图片的阶段，再过几天才能整成想要的样子。</p><p>不得不说，Hexo这类工具真的蛮好用，虽然前期花时间部署比较费劲，但是呈现的效果还是非常不错的，再加上自己可以在原有主题的基础上不断折腾，也是乐趣所在。</p><a id="more"></a><p>第一篇博客主要想把2020年我的计划写下来，经常翻看，保持计划的进度。</p><h2 id="2020年计划"><a href="#2020年计划" class="headerlink" title="2020年计划"></a>2020年计划</h2><h3 id="List"><a href="#List" class="headerlink" title="List"></a>List</h3><p>2020年的计划主要是四个方面：</p><ol><li>搭建个人技术博客 （进行中）</li><li>完成一个数据可视化网站项目</li><li>完成一个微信小程序项目</li><li>微信号/百家号</li></ol><p>希望能在今年把这四件事情按顺序一一搭建起来，即使无法做到完成，也希望能开始行动起来，先找到idea，再把整体思路和框架梳理出来。</p><h3 id="关于个人技术博客"><a href="#关于个人技术博客" class="headerlink" title="关于个人技术博客"></a>关于个人技术博客</h3><p>这部分一直想做，但是没腾出时间来好好研究。最开始还是以WordPress来研究，但由于当时觉得部署麻烦，就没继续。后来做了前端的一些项目之后，生出了自己开发博客网站的想法，无意中在知乎上看到了现在已经如此普遍的Hexo、Hugo等等工具，茅塞顿开。这正是我想要的么！</p><p>那为什么没选Hugo？由于Hexo是基于JavaScript的，Hugo是基于Go语言的，前者对我来说更加熟悉，如果想要在原有基础上折腾，也有很多可以发挥的空间，于是就开开心心地花了一天时间部署到了GitHub Page上。基础工作就算完成了。</p><p>第一版的大概长这样：</p><p><img src="/img/3.jpg" srcset="/img/loading.gif" alt="界面"></p><p>熟悉的 “Hello World”。</p><p>接下来就是确定一下更新的计划了。博客基本根据个人的学习情况和前端开发项目的进展情况来更新，知识的总结、遇到的问题以及其他的感悟放到这上面，作为记录。好记性不如烂笔头。</p><h3 id="关于数据可视化网站项目"><a href="#关于数据可视化网站项目" class="headerlink" title="关于数据可视化网站项目"></a>关于数据可视化网站项目</h3><p>元旦的时候，我原本想把之前写的一个爬虫程序抓到的数据作为这个项目的数据源，不过因为爬虫过程还不完善，而且有些地方仍然需要手动干预，所以关于这个项目的构想就暂时搁置了。</p><p>仔细想想，抛开爬虫实时抓取的需求，仅仅把过往累积的数据拿出来做展示也未尝不可。只不过这样一来，没有办法与爬虫程序整合，只能依靠本地抓取到的数据进行可视化，交互性和功能性会差很多。</p><p>春节期间，再好好考虑一下这个项目。</p><h3 id="关于微信小程序项目"><a href="#关于微信小程序项目" class="headerlink" title="关于微信小程序项目"></a>关于微信小程序项目</h3><p>这个项目需要整体学习小程序开发的语言，目前面临几个问题：第一，开发什么，目前还没有认真思考过，没有清晰的idea；第二，其他的项目在前，这个项目可能要往后面排了，现在时间精力都没办法让我好好想关于这个项目的东西。</p><p>所以，Flag就先立在这吧，回头再来拔。。</p><h3 id="微信号-百家号"><a href="#微信号-百家号" class="headerlink" title="微信号/百家号"></a>微信号/百家号</h3><p>自媒体这部分其实开始了很长时间，但是没能坚持下来，断断续续更新，还没得原创头衔，稍显动力不足。</p><p>春节期间的计划是，拿另一个身份重新注册一个公众号，把百家号上发过的文章拿到公众号的平台上重新发一遍。</p><p>其次，争取恢复百家号的日常更新，考虑到自己犯懒，先定在每周末更新一到两篇。</p><p>每年都是Flag自豪的立起来，年终的时候大部分倒下。可能这就是三三同学生活的常态吧。可三三同学也不应该当一条咸鱼，还是要奋力折腾啊！</p><p><strong>がんばって！</strong></p>]]></content>
    
    
    <categories>
      
      <category>计划</category>
      
    </categories>
    
    
    <tags>
      
      <tag>个人</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
