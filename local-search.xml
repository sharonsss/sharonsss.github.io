<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Java 程序打包之后，替换 jar 包内的文件</title>
    <link href="/2020/04/30/430/"/>
    <url>/2020/04/30/430/</url>
    
    <content type="html"><![CDATA[<p><strong>Java 对我来说绝对是一窍不通，基本陌生。</strong></p><a id="more"></a><p>奈何公司的工程师小伙伴开发了一个Java程序，前端、后端、数据库都是他自己一个人一手搭建起来的，遇到任何问题也只有他才能解决。</p><p>这两天领导一句话，要求把程序里的Logo换掉，可是小伙伴的程序都是打包好的，jar 包里的文件，怎么样替换呢？</p><p>小伙伴也不知道，这种不能像拆口袋一样，直接拆包替换东西。</p><p>下载到本地，在压缩软件里，不解压的情况下直接替换里面的logo文件，再上传到服务器？</p><p>尝试失败。文件在压缩包里替换成功，但上传到服务器，替换原 jar 包之后，运行程序会报错，显示修改打包文件错误。</p><p>看来不能直接这样替换文件？！</p><p><img src="/img/wunai.jpg" srcset="/img/loading.gif" alt="wunai"></p><p>之后百度才找到正确方法：</p><h2 id="替换-jar-包中指定文件"><a href="#替换-jar-包中指定文件" class="headerlink" title="替换 jar 包中指定文件"></a>替换 jar 包中指定文件</h2><ol><li><strong>找到 jar 包中指定文件的路径：</strong></li></ol><pre><code>jar -tvf test.jar | grep logo.svg</code></pre><ol start="2"><li><strong>解压指定路径下的文件</strong></li></ol><pre><code>jar -xvf test.jar conf/logo.svg</code></pre><p>会自动在当前路径下创建目录。</p><ol start="3"><li><strong>把需要替换的文件删除</strong></li></ol><pre><code>rm -rf conf/logo.svg</code></pre><ol start="4"><li><strong>上传文件到替换文件的目录下</strong></li></ol><pre><code class="terminal">$ scp 本地目录 服务器目录（绝对路径）</code></pre><ol start="5"><li><strong>更新到 jar 包中</strong></li></ol><pre><code>jar -uvf test.jar conf/logo.svg</code></pre><hr><p><strong>参考来源：</strong></p><ul><li><em><a href="https://blog.csdn.net/u011817217/article/details/92411009" target="_blank" rel="noopener">使用jar命令替换jar包中指定文件</a></em></li></ul>]]></content>
    
    
    <categories>
      
      <category>Java 程序</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux 服务器根目录空间不足与 Nginx 重启</title>
    <link href="/2020/04/24/420/"/>
    <url>/2020/04/24/420/</url>
    
    <content type="html"><![CDATA[<p>近期运营的产品碰到了服务器的问题，断断续续的无法访问，部署在上面的系统也因此500了。对我这个服务器小白来说，感觉坑好多，再加上同事隔离在家，没办法面对面请教解决的办法，着实心塞了一段时间。</p><a id="more"></a><p>还好今天早上试着访问了一下服务器，居然能进去，赶紧找同样来到公司上班的同事，教我如何解决。</p><h1 id="访问-Linux-服务器、暂时解决根目录空间不足的问题"><a href="#访问-Linux-服务器、暂时解决根目录空间不足的问题" class="headerlink" title="访问 Linux 服务器、暂时解决根目录空间不足的问题"></a>访问 Linux 服务器、暂时解决根目录空间不足的问题</h1><p>服务器无法远程访问，核心的问题是（根据公司负责所有服务器运维的同事所说），这台服务器因为“根目录空间不足”，导致 <code>ssh</code> 无法访问，而我们并非运维，都需要 <code>ssh</code> 远程访问。</p><p>服务器的根目录空间不足？？这个问题咋解决，我一脸黑人问号？？</p><p>无奈，今天早晨能访问了之后，我就进去看了一下，进到根目录里 <code>df -hl</code> 得到下面的信息：</p><pre><code>Filesystem                 Size  Used Avail Use% Mounted on/dev/mapper/centos-root     17G   17G    0G 100% /devtmpfs                   7.8G     0  7.8G   0% /devtmpfs                      7.8G     0  7.8G   0% /dev/shmtmpfs                      7.8G  829M  7.0G  11% /runtmpfs                      7.8G     0  7.8G   0% /sys/fs/cgroup/dev/sda1                 1014M  235M  780M  24% /boot/dev/mapper/datavg-datalv  500G  1.1G  499G   1% /datatmpfs                      1.6G  8.0K  1.6G   1% /run/user/42cm_processes               7.8G     0  7.8G   0% /run/cloudera-scm-agent/processtmpfs                      1.6G     0  1.6G   0% /run/user/1000tmpfs                      1.6G   40K  1.6G   1% /run/user/0</code></pre><p><code>/</code> 根目录100%的空间没有一点剩余？？而且下面几项的总和并没有到100%，这是为啥？又是一脸黑人问号。。</p><p>询问我们这个系统部署的同事，说会不会是日志文件占用空间太多，删一删。然而我并不知道是哪个目录里的日志可以删，哪个又不可以。于是只好找来另外一个做大数据的同事（曾经负责过一段时间这个服务器的人），试着看一看。因为这个同事曾经在这台服务器上安装过 hadoop、hive 相关的东西，占用了一些空间（现在已经不用了）。于是一番操作，删掉了相关的 <code>log</code> 文件夹。</p><p>这些文件相关的细节我不是很懂，再加上 linux 服务器的操作，我其实之前也没有太多实操过，所以看着 <code>terminal</code> 里一行一行的数据，略略感觉自己果真是个小白。</p><p>说回来，删掉一部分日志文件之后，释放出来了4.1G的空间，按照比例来说，清掉了24%的空间，可以说是大进步了！</p><pre><code>Filesystem                 Size  Used Avail Use% Mounted on/dev/mapper/centos-root     17G   13G  4.2G  76% /devtmpfs                   7.8G     0  7.8G   0% /devtmpfs                      7.8G     0  7.8G   0% /dev/shmtmpfs                      7.8G  829M  7.0G  11% /runtmpfs                      7.8G     0  7.8G   0% /sys/fs/cgroup/dev/sda1                 1014M  235M  780M  24% /boot/dev/mapper/datavg-datalv  500G  1.1G  499G   1% /datatmpfs                      1.6G  8.0K  1.6G   1% /run/user/42cm_processes               7.8G     0  7.8G   0% /run/cloudera-scm-agent/processtmpfs                      1.6G     0  1.6G   0% /run/user/1000tmpfs                      1.6G   40K  1.6G   1% /run/user/0</code></pre><p>再有一些无用的安装包之类，也是可以删掉的。</p><p>至此，我们的系统目前已经可以访问了。说实话，根目录的空间简直不要太小喔 😓。</p><p>相对根本的解决办法：</p><p><strong>让运维同事看看能否调整根目录的空间，给大点，也有能伸缩的余地。</strong></p><p>PS：</p><p>查看服务器空间的空间目录情况：</p><pre><code>df -h    查看整台服务器的硬盘使用情况df -hl  可以加上参数查看磁盘剩余空间信息cd /    进入根目录cd ..   回到上层目录du -sh *    查看每个文件夹的大小</code></pre><br><h1 id="Nginx-查看进程、重启"><a href="#Nginx-查看进程、重启" class="headerlink" title="Nginx 查看进程、重启"></a>Nginx 查看进程、重启</h1><p>还有一个问题，是 Nginx 会在一些时候 down 掉。</p><p>Nginx 同 Apache 一样都是一种 Web 服务器。官方的说法：</p><blockquote><p>Nginx 是一款自由的、开源的、高性能的 HTTP 服务器和反向代理服务器；同时也是一个 IMAP、POP3、SMTP 代理服务器。Nginx 可以作为一个 HTTP 服务器进行网站的发布处理，另外 Nginx 可以作为反向代理进行负载均衡的实现。</p></blockquote><p>我们用 Nginx 主要来做图片服务器，配置图片路径。Nginx down 掉之后，需要重启。经过和部署系统的同事请教之后，在这里记录下。</p><ul><li>首先，进入到系统部署的路径，重启系统。</li></ul><pre><code>[root@bigdata001 dataxx]$sudo XXXReboot.sh</code></pre><ul><li>之后，<code>ps -ef | grep nginx</code> 查询出 Nginx 的主进程号。</li></ul><pre><code>ps -ef | grep nginx</code></pre><ul><li>Kill 查询出的进程号：</li></ul><pre><code>sudo kill -9 进程号</code></pre><ul><li>kill 完进程之后，再次 <code>ps -ef | grep nginx</code> 查询进程号是否已被 kill 掉。若kill 进程时，<code>operation not permitted</code> 则是权限不够，需要前加上 <code>sudo</code>。</li></ul><pre><code>ps -ef | grep nginx</code></pre><ul><li>再然后，cd进入sbin目录    ./nginx nginx 目录，<code>./nginx</code> 重启 nginx。</li></ul><pre><code>./nginx</code></pre><p>做完上面这些，系统就可以正常访问了。</p><p>查了一下原因，可能是服务器本身根目录空间不足之后，Nginx 也被迫中断。</p><p>实操的方法记录在这里，如果以后还出现一样的问题，我也可以找到解决办法。</p><br><p>PS：封面上小企鹅迷人的微笑送给我自己 😂。</p><br>]]></content>
    
    
    <categories>
      
      <category>服务器</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
      <tag>Nginx</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>jQuery、HTML、CSS中的小细节汇总（一）</title>
    <link href="/2020/04/15/0415-1/"/>
    <url>/2020/04/15/0415-1/</url>
    
    <content type="html"><![CDATA[<p>这个博客其中一个目的，是一边开发前端页面，一边记录下自己遇到的问题，很多是非常有tricks的，之后也可能会频繁用到。</p><p>下边主要总结的是 jQuery 和 CSS 中的一些小细节，之后如果积累了更多的点，再补充第二篇。</p><a id="more"></a><br><h1 id="HTML-中获取-lt-span-gt-标签内的值-jQuery"><a href="#HTML-中获取-lt-span-gt-标签内的值-jQuery" class="headerlink" title="HTML 中获取 &lt;span&gt; 标签内的值 - jQuery"></a>HTML 中获取 <code>&lt;span&gt;</code> 标签内的值 - jQuery</h1><p>在 jQuery 中，获取 HTML 中各个标签内值的方法有几个。</p><p>最近遇到了如何获取 <code>&lt;span&gt;</code> 标签内的值的问题，试验了一下几种获取值的方法：</p><pre><code class="html">&lt;html&gt;  &lt;head&gt;    &lt;script language=JavaScript src=&quot;js/jquery.min.js&quot;&gt;&lt;/script&gt;  &lt;/head&gt;  &lt;body&gt;     &lt;span id=&quot;spId&quot;&gt;show me&lt;/span&gt;     &lt;script language=JavaScript&gt;       var test1 = $(&quot;#spId&quot;).val();       var test2 = $(&quot;#spId&quot;).html();       var test3 = $(&quot;#spId&quot;).text();       alert(&quot;val: &quot;  + test1);       alert(&quot;html: &quot; + test2);       alert(&quot;text: &quot; + test3);     &lt;/script&gt;  &lt;/body&gt;&lt;/html&gt;</code></pre><p>三种获取所得的值分别为：</p><pre><code>val: 空html: show metext: show me</code></pre><p>因此，</p><ul><li><p>获取input的信息时，可以用 <code>val()</code></p></li><li><p>获取 <code>&lt;span&gt;</code> 的值，可以用 <code>html()</code> 或者 <code>text()</code></p></li></ul><br><h1 id="CSS-中-active-选择器的用法"><a href="#CSS-中-active-选择器的用法" class="headerlink" title="CSS 中 active 选择器的用法"></a>CSS 中 <code>active</code> 选择器的用法</h1><p>CSS 选择器 <code>active</code> 代表元素被激活（按下）时的样式。“激活”是指从点击模块后直到松开模块的过程。</p><p>例如：</p><pre><code class="css">a:active{  background-color: yellow;}</code></pre><p>来一个简单的实现例子：</p><pre><code class="html">&lt;!DOCTYPE html&gt;&lt;html&gt;  &lt;head&gt;    &lt;style&gt;      a:active      {        background-color:yellow;      }    &lt;/style&gt;  &lt;/head&gt;  &lt;body&gt;    &lt;a href=&quot;http://www.google.com&quot;&gt;Google&lt;/a&gt;  &lt;/body&gt;&lt;/html&gt;</code></pre><p><strong>另外，需要注意一个区别：</strong></p><ul><li><p><code>a.active</code> 是对<code>class=active</code>的<code>a</code>标签生效</p></li><li><p><code>a:active</code> 是对按下的<code>a</code>标签生效</p></li></ul><p>两者所代表的内涵是不一样的。</p><p>此外，<code>active</code> 也可以实现元素 <code>display:none</code> 和 <code>display:block</code> 的切换。</p><br><h1 id="CSS-设置背景、背景图片、blur效果"><a href="#CSS-设置背景、背景图片、blur效果" class="headerlink" title="CSS 设置背景、背景图片、blur效果"></a>CSS 设置背景、背景图片、blur效果</h1><ul><li><p><code>background: url(&#39;url&#39;)</code> 用来设置背景图片，后边可以加 <code>no-repeat</code> 限制是否重复平铺图像</p></li><li><p><code>background-position</code> 和 <code>background-size</code> 用来调整图片的显示方式</p></li></ul><pre><code class="css">.bg {      background: url(&#39;1.jpg&#39;) no-repeat;      height:600px;      width: 100%;      text-align: center;      line-height: 600px;      background-position: center;      background-size: cover;  }</code></pre><ul><li><p>最简单粗暴的设置 blur 的方法，是直接加上 <code>filter: blur(3px)</code> 的属性。但是，这样会导致背景图所在 <code>&lt;div&gt;</code> 内的其他元素，包括文字，都会虚化。解决办法有两种：</p><ul><li><p>第一，将背景图片单独放到一个div里，这样就不会和其他元素的效果有冲突</p></li><li><p>第二，通过 <code>:before</code> 的状态和 <code>z-index</code> 来控制，只让背景图片虚化。举个例子：</p></li></ul></li></ul><pre><code class="css">.demo1{    width: 500px;    height: 300px;    line-height: 50px;    text-align: center;}.demo1:before{    background: url(http://csssecrets.io/images/tiger.jpg) no-repeat;    background-size: cover;    width: 500px;    height: 300px;    content: &quot;&quot;;    position: absolute;    top: 0;    left: 0;    z-index: -1;/*-1 可以当背景*/    -webkit-filter: blur(3px);    filter: blur(3px);}&lt;div class=&quot;demo1&quot;&gt;背景图半透明，文字不透明&lt;br/&gt;  方法：背景图+ filter：blur&lt;/div&gt;</code></pre><p>这种设置可以在不改变div结构的情况下，使背景图片虚化。</p><hr><p><strong>参考来源：</strong></p><ul><li><em><a href="https://blog.csdn.net/qq_37540004/article/details/78280454" target="_blank" rel="noopener">css实现 display: none和display: block的切换动画</a></em></li><li><em><a href="https://blog.csdn.net/xiaoxiao20121314/article/details/81103500" target="_blank" rel="noopener">CSS样式的状态hover、focus、active、link、visited详解</a></em></li><li><em><a href="https://www.jianshu.com/p/12a938e5c557" target="_blank" rel="noopener">CSS实现背景图片透明和文字不透明效果</a></em></li></ul>]]></content>
    
    
    <categories>
      
      <category>前端开发</category>
      
    </categories>
    
    
    <tags>
      
      <tag>jQuery</tag>
      
      <tag>CSS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>jQuery需要注意的几个小点</title>
    <link href="/2020/04/11/jquery/"/>
    <url>/2020/04/11/jquery/</url>
    
    <content type="html"><![CDATA[<p>最近在写一个前端的搜索页面，主要思路是从Elasticsearch拿到数据，并在前端做搜索查询的极简页面。ES有提供现成的Javascript API，既有后端Node.js的版本，也有直接从client端就可以获取数据对的接口。<a id="more"></a></p><p>我这次最开始用的是基于Client端直接获取数据的版本。（因为Node.js传参我还搞不太清楚。。）</p><p>前端的实现主要基于原生JavaScript和jQuery，记录下遇到的一些问题。</p><h2 id="1-jQuery-引用链接的位置"><a href="#1-jQuery-引用链接的位置" class="headerlink" title="1. jQuery 引用链接的位置"></a>1. jQuery 引用链接的位置</h2><p>jQuery在html文件中引用的<code>&lt;script&gt;</code>位置，要放到<code>&lt;body&gt;</code>标签之后，如果放到<code>&lt;body&gt;</code>标签之前，运行的时候会报错。</p><h2 id="2-lt-form-action-quot-quot-gt-元素"><a href="#2-lt-form-action-quot-quot-gt-元素" class="headerlink" title="2. &lt;form action=&quot;#&quot;&gt; 元素"></a>2. <code>&lt;form action=&quot;#&quot;&gt;</code> 元素</h2><p><code>&lt;form&gt;</code>标签提供了一个<code>action</code>的属性，这个属性的作用是，点击按钮会刷新页面。</p><p>我的页面中写了一个搜索按钮，按钮包含在<code>&lt;form&gt;</code>标签中，于是导致每次我点击“搜索”的时候，页面都会刷新，去掉这个属性就好。</p><h2 id="3-用-jQuery-判定输入的字符是中文还是英文"><a href="#3-用-jQuery-判定输入的字符是中文还是英文" class="headerlink" title="3. 用 jQuery 判定输入的字符是中文还是英文"></a>3. 用 jQuery 判定输入的字符是中文还是英文</h2><p>思路是用正则表达式来识别，同时利用jQuery的<code>.test()</code>方法。基本的正则表达式还要再复习一下。</p><p>判断字符是否为全英文：</p><pre><code class="Javascript">// 判断输入是否为全英文var re=/^[a-zA-Z]+$/;//判断是否包含数字字母下划线  当使用这个时如果只有部分是中文字符还可以使用英文字体var reg=/[A-Za-z]*[a-z0-9_-]|\s$/;if(!re.test(txt)){    return false;}return true;</code></pre><p>判断输入是否为全中文：</p><pre><code class="Javascript">// 判断输入是否为全中文var res=/^[\u4e00-\u9fa5]+$/;if(!res.test(txt)){    return false;}return true;</code></pre><p>我涉及到的字符输入除了英文就是中文，还有少部分的数字，因此先判定英文字符，如果不是英文，那么就是中文或数字了，规则比较简单。</p><h2 id="4-JS-里的-forEach-和-jQuery-里的-each"><a href="#4-JS-里的-forEach-和-jQuery-里的-each" class="headerlink" title="4. JS 里的 forEach() 和 jQuery 里的 each()"></a>4. JS 里的 forEach() 和 jQuery 里的 each()</h2><p>如果参数为一个，这一个参数代表“元素”。JS举例：</p><pre><code class="JavaScript">var arr = new Array([&quot;b&quot;, 2, &quot;a&quot;, 4],[&quot;c&quot;,3,&quot;d&quot;,6]);arr.forEach(function(item){    alert(item);  //b, 2, a, 4和c,3,d,6});</code></pre><p>如果forEach里有两个参数，则第一个参数为该集合里的元素，第二个参数为集合的索引：</p><pre><code class="Javascript">arr.forEach(function(item, i){}</code></pre><p>但是在jQuery中，如果至哟耦哦一个参数，那么这个参数代表“索引”。举例：</p><pre><code class="Javascript">var arr = new Array([&quot;b&quot;, 2, &quot;a&quot;, 4],[&quot;c&quot;,3,&quot;d&quot;,6]);$.each(arr, function(item){    alert(item);  //0;1});</code></pre><p>如果有两个参数，则第一个为索引，第二个该集合里的元素:</p><pre><code class="Javascript">$.each(arr, function(i, item){}</code></pre><h2 id="5-Bootstrap3-typeahead-js-输入框自动补全"><a href="#5-Bootstrap3-typeahead-js-输入框自动补全" class="headerlink" title="5. Bootstrap3-typeahead.js 输入框自动补全"></a>5. Bootstrap3-typeahead.js 输入框自动补全</h2><p>这次做搜索页面，一个重要的功能是允许用户在搜索时，能出现模糊匹配的词汇（中文和英文），于是用了 bootstrap3-typeahead.js 这个插件。</p><p>typeahead的基本逻辑也很简单，通过访问数据库获取JSON数据之后，利用现成的<code>process()</code>函数就可以自动把获取到的数据显示在搜索框中。</p><p>需要注意的是获取的JSON格式，如果数据结构不符合，需要稍微做一些处理，再输入到<code>process</code>函数中。另外，下载的bootstrap3-typeahead.js 在引用时，注意要放到jQuery文件的后面，不然无法调用。</p><p>实现的效果也比较简单，如果有现成的数组，好说：</p><pre><code class="Javascript">$(function () {            var localArrayData = [&#39;beijing&#39;, &#39;shanghai&#39;, &#39;guangzhou&#39;, &#39;tianjin&#39;, &#39;hangzhou&#39;, &#39;ningbo&#39;];            $(&quot;#txtUser&quot;).typeahead({                source: localArrayData            });        });</code></pre><p>这里的<code>source</code>，就是获取到的数据。</p><p>如果是需要调取数据库的数据，<code>typeahead()</code>方法中，要包含参数为<code>query, process</code>的函数，用来获取数据，并通过<code>process()</code>显示出来。</p><p>以ajax为例：</p><pre><code class="Javascript"> $(function () {            $(&quot;#txtUser&quot;).typeahead({                source: function (query, process) {                    $.ajax({                        url: &#39;/Tools/GetOperUsers&#39;,                        data: {                            name: query                        },                        type: &#39;post&#39;,                        dataType: &quot;json&quot;,                        success: function (data) {                            var res = [];                            $.each(data, function (i, item) {                                var aItem = { id: item.CreateUserId, name: item.CreateUserRealName };//把后台传回来的数据处理成带name形式                                res.push(aItem);                            })                            // res 是我们获取到的数据                            return process(res);                        }                    });                }            });        });</code></pre><p>ES数据库的数据调取稍有不同，同样参照client端的JS API。</p><p>我在前端实现之后是这样的：</p><p><img src="/img/typeahead.png" srcset="/img/loading.gif" alt="1"></p><p>效果很简单了。</p><p>后边想自定义调整一下显示栏的样式，如果实现了再补充。</p><h2 id="6-文本框刷新之后，清除原来的输入"><a href="#6-文本框刷新之后，清除原来的输入" class="headerlink" title="6. 文本框刷新之后，清除原来的输入"></a>6. 文本框刷新之后，清除原来的输入</h2><p>这个点解决起来不要太简单!</p><p>只需要在<code>&lt;input&gt;</code>文本输入框中加一条属性<code>autocomplete=&quot;off&quot;</code>，就好了。。</p><p>作用域不只是input标签，form标签同样可以。</p>]]></content>
    
    
    <categories>
      
      <category>前端开发</category>
      
    </categories>
    
    
    <tags>
      
      <tag>jQuery</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Elasticsearch + Kibana 安装记录</title>
    <link href="/2020/04/05/elasticsearch%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95/"/>
    <url>/2020/04/05/elasticsearch%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<p>公司今年的项目要把原来的数据迁移到Elasticsearch数据库中，通过技术负责人的介绍，我才知道了ES+kibana这个组合，开源，可以基于ES数据直接在Kibana上进行数据查询和图表分析。<a id="more"></a> 想我们之前还苦哈哈的自己写Echarts做数据图表，虽然实现了我们最初的需求，但是和采用Kibana比起来，还是占用了不少的时间和精力。</p><p>这几天在本地搭建了ES+Kibana，在此记录一下。</p><h1 id="Elasticsearch-安装"><a href="#Elasticsearch-安装" class="headerlink" title="Elasticsearch 安装"></a>Elasticsearch 安装</h1><h2 id="下载与安装"><a href="#下载与安装" class="headerlink" title="下载与安装"></a>下载与安装</h2><p>Elasticsearch的安装方式相对来说比较简单。<code>brew</code>的安装方式对我来说太慢，于是直接在官网上下载的安装包（公司网太慢，下个安装包还花了一天时间）。</p><ul><li><p>下载地址：<a href="https://www.elastic.co/downloads/elasticsearch" target="_blank" rel="noopener">https://www.elastic.co/downloads/elasticsearch</a></p></li><li><p>安装版本：7.6.2 （与Kibana的版本要一致）</p></li></ul><p>下载完成之后，放到<code>/usr/local/Cellar/</code>路径下，解压。</p><p>进入 bin 目录启动 ES 并在运行：</p><pre><code>$ ./elasticsearch$ ./elasticsearch -d (后台运行)</code></pre><p>curl 测试是否正常运行（或者在浏览器中打开）：</p><pre><code>$ curl 127.0.0.1:9200</code></pre><p>此时出现：</p><pre><code>{  &quot;name&quot; : &quot;mvQoSGm&quot;,  &quot;cluster_name&quot; : &quot;elasticsearch&quot;,  &quot;cluster_uuid&quot; : &quot;4vUSt2_AQFSj5LZDVgR74g&quot;,  &quot;version&quot; : {    &quot;number&quot; : &quot;7.6.2&quot;,    &quot;build_flavor&quot; : &quot;default&quot;,    &quot;build_type&quot; : &quot;tar&quot;,    &quot;build_hash&quot; : &quot;04711c2&quot;,    &quot;build_date&quot; : &quot;2020-04-02T13:34:09.098244Z&quot;,    &quot;build_snapshot&quot; : false,    &quot;lucene_version&quot; : &quot;7.4.0&quot;,    &quot;minimum_wire_compatibility_version&quot; : &quot;6.6.0&quot;,    &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0&quot;  },  &quot;tagline&quot; : &quot;You Know, for Search&quot;</code></pre><p>表示安装成功。</p><p>初步安装之后，我并没有做其他的设置，还有一些插件因为下载路径实在太慢，准备后面再慢慢安装。</p><h2 id="查看ES集群的简单命令"><a href="#查看ES集群的简单命令" class="headerlink" title="查看ES集群的简单命令"></a>查看ES集群的简单命令</h2><h3 id="1-查看集群的健康状态"><a href="#1-查看集群的健康状态" class="headerlink" title="1. 查看集群的健康状态"></a>1. 查看集群的健康状态</h3><pre><code>http://127.0.0.1:9200/_cat/health?v</code></pre><p>URL中_cat表示查看信息，health表明返回的信息为集群健康信息，?v表示返回的信息加上头信息，跟返回JSON信息加上?。</p><ul><li><p>集群的状态（status）：red红表示集群不可用，有故障。yellow黄表示集群不可靠但可用，一般单节点时就是此状态。green正常状态，表示集群一切正常。</p></li><li><p>节点数（node.total）：节点数，这里是2，表示该集群有两个节点。</p></li><li><p>数据节点数（node.data）：存储数据的节点数，这里是2。数据节点在Elasticsearch概念介绍有。</p></li><li><p>分片数（shards）：这是12，表示我们把数据分成多少块存储。</p></li><li><p>主分片数（pri）：primary shards，这里是6，实际上是分片数的两倍，因为有一个副本，如果有两个副本，这里的数量应该是分片数的三倍，这个会跟后面的索引分片数对应起来，这里只是个总数。</p></li><li><p>激活的分片百分比（active_shards_percent）：这里可以理解为加载的数据分片数，只有加载所有的分片数，集群才算正常启动，在启动的过程中，如果我们不断刷新这个页面，我们会发现这个百分比会不断加大。</p></li></ul><p><img src="/img/1.png" srcset="/img/loading.gif" alt="1"></p><h3 id="2-查看集群的索引数"><a href="#2-查看集群的索引数" class="headerlink" title="2. 查看集群的索引数"></a>2. 查看集群的索引数</h3><pre><code>http://127.0.0.1:9200/_cat/indices?v</code></pre><ul><li><p>索引健康（health），green为正常，yellow表示索引不可靠（单节点），red索引不可用。与集群健康状态一致。</p></li><li><p>状态（status），表明索引是否打开。</p></li><li><p>索引名称（index），这里有.kibana和school。</p></li><li><p>uuid，索引内部随机分配的名称，表示唯一标识这个索引。</p></li><li><p>主分片（pri），.kibana为1，school为5，加起来主分片数为6，这个就是集群的主分片数。</p></li><li><p>文档数（docs.count），school在之前的演示添加了两条记录，所以这里的文档数为2。</p></li><li><p>已删除文档数（docs.deleted），这里统计了被删除文档的数量。</p></li><li><p>索引存储的总容量（store.size），这里school索引的总容量为6.4kb，是主分片总容量的两倍，因为存在一个副本。</p></li><li><p>主分片的总容量（pri.store.size），这里school的主分片容量是7kb，是索引总容量的一半。</p></li></ul><p><img src="/img/2.png" srcset="/img/loading.gif" alt="2"></p><h3 id="3-查看集群所在磁盘的分配状况"><a href="#3-查看集群所在磁盘的分配状况" class="headerlink" title="3. 查看集群所在磁盘的分配状况"></a>3. 查看集群所在磁盘的分配状况</h3><pre><code>http://127.0.0.1:9200/_cat/allocation?v</code></pre><p>返回集群中的各节点所在磁盘的磁盘状况。</p><h3 id="4-查看集群的节点"><a href="#4-查看集群的节点" class="headerlink" title="4. 查看集群的节点"></a>4. 查看集群的节点</h3><pre><code>http://127.0.0.1:9200/_cat/nodes?v</code></pre><p>通过该连接返回了集群中各节点的情况。这些信息中比较重要的是master列，带*星号表明该节点是主节点。带-表明该节点是从节点。</p><pre><code>ip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name127.0.0.1 19 99 6 2.86 mdi * ruan-node-1127.0.0.1 13 99 6 2.86 mdi - ruan-node-2</code></pre><h3 id="5-查看集群的其它信息"><a href="#5-查看集群的其它信息" class="headerlink" title="5. 查看集群的其它信息"></a>5. 查看集群的其它信息</h3><pre><code>http://127.0.0.1:9200/_cat/</code></pre><p>获得查看集群信息的目录。</p><h3 id="6-全词搜索"><a href="#6-全词搜索" class="headerlink" title="6. 全词搜索"></a>6. 全词搜索</h3><pre><code>http://127.0.0.1:9200/indexName/_search?pretty=true</code></pre><p><code>pretty=true</code> 表示格式化输出。</p><h3 id="7-精准搜索"><a href="#7-精准搜索" class="headerlink" title="7. 精准搜索"></a>7. 精准搜索</h3><pre><code>http://127.0.0.1:9200/indexName/_search?q=123&amp;pretty=true</code></pre><p>表示搜索“123”。</p><h3 id="8-模糊搜索"><a href="#8-模糊搜索" class="headerlink" title="8. 模糊搜索"></a>8. 模糊搜索</h3><pre><code>http://127.0.0.1:9200/indexName/_search?q=*123*&amp;pretty=true</code></pre><p>模糊搜索“123”。</p><h1 id="Kibana-安装"><a href="#Kibana-安装" class="headerlink" title="Kibana 安装"></a>Kibana 安装</h1><h2 id="下载与安装-1"><a href="#下载与安装-1" class="headerlink" title="下载与安装"></a>下载与安装</h2><p>Kibana安装时要注意与ES是同一个版本，ES我的版本是7.6.2，因此Kibana也下载的7.6.2版本的安装包。</p><ul><li>下载地址同官网</li><li>版本：7.6.2</li></ul><p>下载完成后，同样解压到<code>/usr/local/Cellar/</code>路径下。</p><p>进入kibana中的bin目录中，启动：</p><pre><code>$ ./kibana</code></pre><p>Kibana默认端口号<em>5601</em>， 启动成功后，到浏览器输入<code>hocalhost:5601</code>，就能进入Kibana页面了。</p><p>Kibana 7.x版本界面终于做的好看了一些。公司目前用的是5.x版本，界面简单粗暴，看起来总有些怪怪的。</p><p><img src="/img/kibana_cut.png" srcset="/img/loading.gif" alt="3"></p><p><strong>问题：</strong></p><p>在公司安装时，localhost:5601地址可以直接访问Kibana，但是回到家之后再次访问却提示localhost:5601错误，无法访问了，ES也只能通过127.0.0.1:9200才能访问，localhost：9200显示无法连接。</p><p>后来在<code>kibana.yml</code>配置文件里把localhost改成127.0.0.1之后，才能通过127.0.0.1:5601访问，不知道是不是我改动了一些配置？？</p><p>之后再调整一下看看。</p><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>首先在<code>Management</code>中配置<code>Index Patterns</code>，将想要分析的Index加入进来。</p><p>在<code>Dev Tools</code>里写命令获取数据：</p><pre><code>GET /data_index/_search{  &quot;query&quot;: {    &quot;match_all&quot;: {}  }}</code></pre><p>上面是最简单的获取，Kibana还有其他的Lucene查询语法，可以查询更多的ES数据，按条件查询、搜索等，待实际应用中慢慢学习。</p><p>今天先初步记录安装与使用的信息，以免过后忘记。</p><hr><p><strong>参考来源：</strong></p><ul><li><em><a href="https://blog.csdn.net/genghaihua/article/details/81479619" target="_blank" rel="noopener">ES查看集群信息命令</a></em></li><li><em><a href="https://blog.csdn.net/a544258023/article/details/89709046?depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-2&utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-2" target="_blank" rel="noopener">ElasticSearch常用查询命令</a></em></li></ul>]]></content>
    
    
    <categories>
      
      <category>ELK</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kibana</tag>
      
      <tag>Elasticsearch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Elasticdump 踩坑记录</title>
    <link href="/2020/04/02/elasticdump%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"/>
    <url>/2020/04/02/elasticdump%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<blockquote><p>感觉这几天是自己的智商低谷。😭</p></blockquote><h1 id="Elasticdump-安装"><a href="#Elasticdump-安装" class="headerlink" title="Elasticdump 安装"></a>Elasticdump 安装</h1><p>为了解决远程ES数据库导入到本地ES的问题，今天在网上查了一天资料。了解到ELK中的Logstash可以实现这个需求，同时Logstash似乎还隐藏着更多其他炫酷功能，包括我后面可能要用到的web接口。<a id="more"></a> 感觉到这是一个稍微大点的功能，最终决定后面专门腾出时间来研究。</p><p>于是就找到了另外一个非常轻量级的ElasticSearch插件————Elasticdump，专门解决ES数据导入导出的问题。“dump”也是个非常形象的词了，有些简单粗暴，就跟它的实现一样。</p><p>安装Elasticdump很简单，mac上直接 <code>npm install elasticdump</code> 就好了。也可以全剧安装 <code>npm install elasticdump -g</code> 。</p><h1 id="将远程-ES-数据导出到本地-JSON-文件"><a href="#将远程-ES-数据导出到本地-JSON-文件" class="headerlink" title="将远程 ES 数据导出到本地 JSON 文件"></a>将远程 ES 数据导出到本地 JSON 文件</h1><p>这里演示的是我把远程ES上的数据导出到本地的JSON文件。最初的想法是，把远程ES数据导到本地文件，再把文件导入本地的ES。此时，我并没有想到远程ES和本地ES可以直接导入导出，脑子卡在了本地文件里。😓</p><p>实际output部分为本地文件路径，具体如下：</p><pre><code># 格式：$ elasticdump --input {protocol}://{host}:{port}/{index} --output ./test_index.json# 例子：将ES中的test_index 中的索引导出# 导出当前索引的mapping结构$ elasticdump --input http://192.168.56.104:9200/test_index \--output ./test_index_mapping.json --type=mapping# 导出当前索引下的所有真实数据$ elasticdump --input http://192.168.56.104:9200/test_index \--output ./test_index.json --type=data</code></pre><h1 id="将远程的-ES-数据导出到本地-ES"><a href="#将远程的-ES-数据导出到本地-ES" class="headerlink" title="将远程的 ES 数据导出到本地 ES"></a>将远程的 ES 数据导出到本地 ES</h1><p>本地JSON导出之后，终于想到elasticdump明明可以连接远程和本地ES。。。</p><h2 id="无账号密码的情况下导出"><a href="#无账号密码的情况下导出" class="headerlink" title="无账号密码的情况下导出"></a>无账号密码的情况下导出</h2><p>如果远程和本地的ES都不需要账号密码访问权限，相对来说就比较容易，直接遵循下面的格式就可以。</p><p>官方提供的数据迁移示例：</p><pre><code># 拷贝analyzer分词elasticdump \  --input=http://production.es.com:9200/my_index \  --output=http://staging.es.com:9200/my_index \  --type=analyzer</code></pre><pre><code># 拷贝映射elasticdump \  --input=http://production.es.com:9200/my_index \  --output=http://staging.es.com:9200/my_index \  --type=mapping</code></pre><pre><code># 拷贝数据elasticdump \  --input=http://production.es.com:9200/my_index \  --output=http://staging.es.com:9200/my_index \  --type=data</code></pre><h2 id="设置账号密码登录导出"><a href="#设置账号密码登录导出" class="headerlink" title="设置账号密码登录导出"></a>设置账号密码登录导出</h2><p><strong>据说 elasticdump 提供给了–httpAuthFile 参数来做认证</strong></p><pre><code>--httpAuthFile      When using http auth provide credentials in ini file in form                    `user=&lt;username&gt;                    password=&lt;password&gt;`</code></pre><p>只需要写一个ini文件 ，文件中写入用户名和密码就可以了，不过这个方法我还没有试。</p><p>另外一个好的方法是，<strong>在–input参数和–output参数的的url中添加账号密码</strong>。</p><p>例如：</p><pre><code>$ elasticdump --input http://username:passowrd@production.es.com:9200/my_index \--output http://username:password@staging.es.com:9200/my_index \--type=data</code></pre><p>导出mapping</p><pre><code>$ elasticdump --input http://username:password@host:9200/data_index \--output ./test_index.json --type=mapping</code></pre><p>导出所有data</p><pre><code>$ elasticdump --input http://username:password@host:9200/data_index \--output ./test_index_data.json --type=data</code></pre><h2 id="远程-ES-需要账号密码，本地不需要"><a href="#远程-ES-需要账号密码，本地不需要" class="headerlink" title="远程 ES 需要账号密码，本地不需要"></a>远程 ES 需要账号密码，本地不需要</h2><p><strong>上面看起来行云流水一般就能搞定，事实上，对小白来说，好大的坑啊。。。</strong></p><p>折腾完上面的远程ES导出到本地JSON之外，突然发现可以直接从远程ES导入本地ES，为什么我还要拐个弯导出个本地文件，服了我自己的智商。。。</p><p><img src="/img/zhishang1.jpg" srcset="/img/loading.gif" alt="智商"></p><p>由于本地ES没有任何配置，于是我按照示例，最初想到了这样：</p><pre><code>$ elasticdump --input http://username:password@0.0.0.0:9200/data_index \--output http://localhost:9200/data_index --type=mapping</code></pre><p>报错：</p><pre><code>Error Emitted =&gt; {&quot;root_cause&quot;:[{&quot;type&quot;:&quot;mapper_parsing_exception&quot;,&quot;reason&quot;:&quot;Root mapping definition has unsupported parameters:  [kis_data_index_type : {properties={eng_exam_res={type=keyword}, item_state={type=keyword}, first_level={type=text}, chin_exam={analyzer=ik_max_word, type=text}, chinese_item={analyzer=ik_max_word, type=text}, xremark={type=keyword}, eng_synonym={type=keyword}, eng_exam={type=text}, contributor={type=text}, third_level={type=text}, chin_exam_res={type=keyword}, id={type=long}, remark_str={type=keyword}, chin_define_res={type=keyword}, chin_synonym={type=text}, eng_abbr={type=text}, contributor ={type=text, fields={keyword={ignore_above=256, type=keyword}}}, query={properties={match_all={type=object}}}, source_type={type=keyword}, english_item={analyzer=english, type=text}, second_level={type=text}, eng_define_res={type=keyword}, eng_define={type=text}, picture_res={type=keyword}, chin_abbr={type=text}, chin_define={type=text}}}]&quot;}],&quot;type&quot;:&quot;mapper_parsing_exception&quot;,&quot;reason&quot;:&quot;Root mapping definition has unsupported parameters:  [kis_data_index_type : {properties={eng_exam_res={type=keyword}, item_state={type=keyword}, first_level={type=text}, chin_exam={analyzer=ik_max_word, type=text}, chinese_item={analyzer=ik_max_word, type=text}, xremark={type=keyword}, eng_synonym={type=keyword}, eng_exam={type=text}, contributor={type=text}, third_level={type=text}, chin_exam_res={type=keyword}, id={type=long}, remark_str={type=keyword}, chin_define_res={type=keyword}, chin_synonym={type=text}, eng_abbr={type=text}, contributor ={type=text, fields={keyword={ignore_above=256, type=keyword}}}, query={properties={match_all={type=object}}}, source_type={type=keyword}, english_item={analyzer=english, type=text}, second_level={type=text}, eng_define_res={type=keyword}, eng_define={type=text}, picture_res={type=keyword}, chin_abbr={type=text}, chin_define={type=text}}}]&quot;}Error Emitted =&gt; {&quot;root_cause&quot;:[{&quot;type&quot;:&quot;mapper_parsing_exception&quot;,&quot;reason&quot;:&quot;Root mapping definition has unsupported parameters:  [kis_data_index_type : {properties={eng_exam_res={type=keyword}, item_state={type=keyword}, first_level={type=text}, chin_exam={analyzer=ik_max_word, type=text}, chinese_item={analyzer=ik_max_word, type=text}, xremark={type=keyword}, eng_synonym={type=keyword}, eng_exam={type=text}, contributor={type=text}, third_level={type=text}, chin_exam_res={type=keyword}, id={type=long}, remark_str={type=keyword}, chin_define_res={type=keyword}, chin_synonym={type=text}, eng_abbr={type=text}, contributor ={type=text, fields={keyword={ignore_above=256, type=keyword}}}, query={properties={match_all={type=object}}}, source_type={type=keyword}, english_item={analyzer=english, type=text}, second_level={type=text}, eng_define_res={type=keyword}, eng_define={type=text}, picture_res={type=keyword}, chin_abbr={type=text}, chin_define={type=text}}}]&quot;}],&quot;type&quot;:&quot;mapper_parsing_exception&quot;,&quot;reason&quot;:&quot;Root mapping definition has unsupported parameters:  [kis_data_index_type : {properties={eng_exam_res={type=keyword}, item_state={type=keyword}, first_level={type=text}, chin_exam={analyzer=ik_max_word, type=text}, chinese_item={analyzer=ik_max_word, type=text}, xremark={type=keyword}, eng_synonym={type=keyword}, eng_exam={type=text}, contributor={type=text}, third_level={type=text}, chin_exam_res={type=keyword}, id={type=long}, remark_str={type=keyword}, chin_define_res={type=keyword}, chin_synonym={type=text}, eng_abbr={type=text}, contributor ={type=text, fields={keyword={ignore_above=256, type=keyword}}}, query={properties={match_all={type=object}}}, source_type={type=keyword}, english_item={analyzer=english, type=text}, second_level={type=text}, eng_define_res={type=keyword}, eng_define={type=text}, picture_res={type=keyword}, chin_abbr={type=text}, chin_define={type=text}}}]&quot;}</code></pre><p>应该是不能直接用localhost。</p><p>于是我又试了这样：</p><pre><code>$ elasticdump --input http://username:password@0.0.0.0:9200/kis_data_index \--output http://127.0.0.1:9200/data_index --type=mapping</code></pre><p>本机地址，没错吧？</p><p>依然报同样的错误。</p><p>于是，我寻思着是不是应该用电脑无线的IP？(我还加了公司无线网的账号密码。。)</p><pre><code>$ elasticdump --input http://username:password@0.0.0.0:9200/data_index \--output http://OA:password@10.9.1.000:9200/data_index --type=mapping</code></pre><p>这次报错是连不上：</p><pre><code>Thu, 02 Apr 2020 08:01:54 GMT | starting dumpThu, 02 Apr 2020 08:01:54 GMT | got 1 objects from source elasticsearch (offset: 0)Thu, 02 Apr 2020 08:02:14 GMT | Error Emitted =&gt; connect ECONNREFUSED 0.0.0.0:9200Thu, 02 Apr 2020 08:02:14 GMT | Error Emitted =&gt; connect ECONNREFUSED 0.0.0.0:9200Thu, 02 Apr 2020 08:02:14 GMT | Total Writes: 0Thu, 02 Apr 2020 08:02:14 GMT | dump ended with error (get phase) =&gt; Error: connect ECONNREFUSED 0.0.0.0:9200:9200</code></pre><p>把账号密码去了，还是提示连不上。</p><p>这时候我才看到指令最后的 –type=mapping。</p><p>不会是这个指令多余了吧？？</p><p>删掉之后，果然通了。。</p><pre><code>$ elasticdump --input http://username:password@0.0.0.0:9200/data_index \--output http://127.0.0.1:9200/data_index</code></pre><p><strong>妈蛋!</strong><br><strong>被自己气吐血！！</strong></p><pre><code>Thu, 02 Apr 2020 08:24:37 GMT | starting dumpThu, 02 Apr 2020 08:24:37 GMT | got 100 objects from source elasticsearch (offset: 0)Thu, 02 Apr 2020 08:24:38 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:38 GMT | got 100 objects from source elasticsearch (offset: 100)Thu, 02 Apr 2020 08:24:38 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:38 GMT | got 100 objects from source elasticsearch (offset: 200)Thu, 02 Apr 2020 08:24:38 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:38 GMT | got 100 objects from source elasticsearch (offset: 300)Thu, 02 Apr 2020 08:24:38 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:38 GMT | got 100 objects from source elasticsearch (offset: 400)Thu, 02 Apr 2020 08:24:38 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:38 GMT | got 100 objects from source elasticsearch (offset: 500)Thu, 02 Apr 2020 08:24:38 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:42 GMT | got 100 objects from source elasticsearch (offset: 600)Thu, 02 Apr 2020 08:24:42 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:42 GMT | got 100 objects from source elasticsearch (offset: 700)Thu, 02 Apr 2020 08:24:43 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:43 GMT | got 100 objects from source elasticsearch (offset: 800)Thu, 02 Apr 2020 08:24:43 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:43 GMT | got 100 objects from source elasticsearch (offset: 900)Thu, 02 Apr 2020 08:24:43 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:43 GMT | got 100 objects from source elasticsearch (offset: 1000)Thu, 02 Apr 2020 08:24:43 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:48 GMT | got 100 objects from source elasticsearch (offset: 1100)Thu, 02 Apr 2020 08:24:48 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:48 GMT | got 100 objects from source elasticsearch (offset: 1200)Thu, 02 Apr 2020 08:24:48 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:48 GMT | got 100 objects from source elasticsearch (offset: 1300)Thu, 02 Apr 2020 08:24:48 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:48 GMT | got 100 objects from source elasticsearch (offset: 1400)Thu, 02 Apr 2020 08:24:48 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:48 GMT | got 100 objects from source elasticsearch (offset: 1500)Thu, 02 Apr 2020 08:24:48 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:52 GMT | got 100 objects from source elasticsearch (offset: 1600)Thu, 02 Apr 2020 08:24:52 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:53 GMT | got 100 objects from source elasticsearch (offset: 1700)Thu, 02 Apr 2020 08:24:53 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:53 GMT | got 100 objects from source elasticsearch (offset: 1800)Thu, 02 Apr 2020 08:24:53 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:53 GMT | got 100 objects from source elasticsearch (offset: 1900)Thu, 02 Apr 2020 08:24:53 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:24:53 GMT | got 100 objects from source elasticsearch (offset: 2000)Thu, 02 Apr 2020 08:24:53 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:08 GMT | got 100 objects from source elasticsearch (offset: 2100)Thu, 02 Apr 2020 08:25:08 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:08 GMT | got 100 objects from source elasticsearch (offset: 2200)Thu, 02 Apr 2020 08:25:08 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:08 GMT | got 100 objects from source elasticsearch (offset: 2300)Thu, 02 Apr 2020 08:25:08 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:08 GMT | got 100 objects from source elasticsearch (offset: 2400)Thu, 02 Apr 2020 08:25:08 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:08 GMT | got 100 objects from source elasticsearch (offset: 2500)Thu, 02 Apr 2020 08:25:08 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:08 GMT | got 100 objects from source elasticsearch (offset: 2600)Thu, 02 Apr 2020 08:25:08 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:13 GMT | got 100 objects from source elasticsearch (offset: 2700)Thu, 02 Apr 2020 08:25:13 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:13 GMT | got 100 objects from source elasticsearch (offset: 2800)Thu, 02 Apr 2020 08:25:13 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:13 GMT | got 100 objects from source elasticsearch (offset: 2900)Thu, 02 Apr 2020 08:25:13 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:13 GMT | got 100 objects from source elasticsearch (offset: 3000)Thu, 02 Apr 2020 08:25:13 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:13 GMT | got 100 objects from source elasticsearch (offset: 3100)Thu, 02 Apr 2020 08:25:13 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:18 GMT | got 100 objects from source elasticsearch (offset: 3200)Thu, 02 Apr 2020 08:25:18 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:18 GMT | got 100 objects from source elasticsearch (offset: 3300)Thu, 02 Apr 2020 08:25:18 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:18 GMT | got 100 objects from source elasticsearch (offset: 3400)Thu, 02 Apr 2020 08:25:18 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:18 GMT | got 100 objects from source elasticsearch (offset: 3500)Thu, 02 Apr 2020 08:25:18 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:18 GMT | got 100 objects from source elasticsearch (offset: 3600)Thu, 02 Apr 2020 08:25:18 GMT | sent 100 objects to destination elasticsearch, wrote 100Thu, 02 Apr 2020 08:25:23 GMT | got 35 objects from source elasticsearch (offset: 3700)Thu, 02 Apr 2020 08:25:23 GMT | sent 35 objects to destination elasticsearch, wrote 35Thu, 02 Apr 2020 08:25:23 GMT | got 0 objects from source elasticsearch (offset: 3735)Thu, 02 Apr 2020 08:25:23 GMT | Total Writes: 3735Thu, 02 Apr 2020 08:25:23 GMT | dump complete</code></pre><p>不过，我在网上研究的时候，看到示例中都有指定–type=XXX，mapping和data要分别指定。后边需要验证一下不指定–type的情况下，导入到本地ES的文件是不是同时包含了mapping和所有data数据（从导入的记录上看，确实完整导入了3735条数据）。</p><hr><p><strong>2020-04-03 补充：</strong></p><p>后来想到，–type无法访问可能是因为index指定的问题，后边遇到搜索查询数据的时候，再研究一下。</p>]]></content>
    
    
    <categories>
      
      <category>ELK</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Elasticsearch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>知识点（一）：MVVM模型</title>
    <link href="/2020/03/23/%E7%9F%A5%E8%AF%86%E7%82%B9%E4%B8%80/"/>
    <url>/2020/03/23/%E7%9F%A5%E8%AF%86%E7%82%B9%E4%B8%80/</url>
    
    <content type="html"><![CDATA[<p>在学习Vue的过程中，最先遇到的就是MVVM、耦合、解耦的概念，在这里用“知识点”的分类总结一下。</p><p>知识点的帖子应该会不断增加，积少成多做成一个系列，慢慢充实起来。<a id="more"></a></p><hr><h2 id="MVVM模型"><a href="#MVVM模型" class="headerlink" title="MVVM模型"></a>MVVM模型</h2><p>MVVM是Model-View-ViewModel的缩写，一种前端开发的模型。主要思想是，在前端页面中，把Model用纯JavaScript对象表示，View负责显示，两者做到了最大程度的分离。</p><p>在MVVM架构下，View和Model之间没有直接的联系，而是通过ViewModel来交互，View数据的变化会同步到Model中，Model数据的变化也会立即反应到View上。</p><p><img src="/img/mvvm2.png" srcset="/img/loading.gif" alt="mvvm"></p><br><p>一个MVVM框架和传统JS、jQuery操作DOM的区别是什么？</p><h3 id="传统-JS-操作DOM"><a href="#传统-JS-操作DOM" class="headerlink" title="传统 JS 操作DOM"></a>传统 JS 操作DOM</h3><p>传统的JS直接写代码逻辑去操作DOM，原生JS：</p><pre><code class="html">&lt;!-- HTML --&gt;&lt;span id=&quot;name&quot;&gt;&lt;/span&gt;</code></pre><pre><code class="js">var dom = document.getElementById(&#39;name&#39;);dom.innerHTML = &#39;Sansan&#39;;dom.style.color = &#39;red&#39;</code></pre><h3 id="jQuery-修改-DOM"><a href="#jQuery-修改-DOM" class="headerlink" title="jQuery 修改 DOM"></a>jQuery 修改 DOM</h3><pre><code class="html">&lt;!-- HTML --&gt;&lt;span id=&quot;name&quot;&gt;&lt;/span&gt;</code></pre><p>用 jQuery 修改 DOM：</p><pre><code class="js">$(&#39;#name&#39;).text(&quot;Sansan&quot;).css(&quot;color&quot;, &quot;red&quot;);</code></pre><p>jQuery中数据处理的逻辑和视图混合在一起，并未分离。</p><h3 id="MVVM-修改-DOM"><a href="#MVVM-修改-DOM" class="headerlink" title="MVVM 修改 DOM"></a>MVVM 修改 DOM</h3><p>只需要关注数据结构，由 ViewModel 进行双向绑定数据操作：</p><pre><code class="html">&lt;!-- HTML --&gt;&lt;div id=&quot;app&quot;&gt;    &lt;input v-model=&quot;name&quot; /&gt;    &lt;span&gt;姓名:{{name}}&lt;/span&gt;    &lt;span&gt;年龄:{{age}}&lt;/span&gt;&lt;/div&gt;</code></pre><p>Vue.js</p><pre><code class="js">var app = new Vue({    el: &#39;#app&#39;,    data: {        name: &#39;Sansan&#39;,        age: 20    }})</code></pre><p>Vue.js 将数据视图分离，以数据驱动视图，只关心数据变化，DOM操作被封装。</p><h2 id="耦合与解耦"><a href="#耦合与解耦" class="headerlink" title="耦合与解耦"></a>耦合与解耦</h2><h3 id="耦合"><a href="#耦合" class="headerlink" title="耦合"></a>耦合</h3><p>软件工程中，对象之间的耦合度就是对象之间的依赖性。对象之间耦合越高，维护成本越高，因此对象的设计应该使类和构件之间的耦合最小。耦合性用来衡量程序结构中各个模块之间的相互关联，同时取决于各个模块之间接口的复杂程度、调用模块的方式是什么，以及哪些信息通过接口。</p><h3 id="解耦"><a href="#解耦" class="headerlink" title="解耦"></a>解耦</h3><p>解耦即尽可能减少代码之间的耦合，数据、业务和视图之间尽可能的降低耦合。</p><p>原则就是A功能的代码不要写在B的功能代码中，如果两者之间需要交互，可以通过接口，通过消息，甚至可以引入框架，但总之就是不要直接交叉写。</p><p>在Vue中，解耦即将<strong>视图</strong>与<strong>数据</strong>分成两部分，即<strong>视图代码</strong>与<strong>业务逻辑</strong>的解耦。</p><hr><p><strong>参考来源：</strong></p><ul><li><em><a href="https://www.liaoxuefeng.com/wiki/1022910821149312/1108898947791072" target="_blank" rel="noopener">廖雪峰的官方网站</a></em></li><li><em><a href="https://blog.csdn.net/zhanghuali0210/article/details/82287544?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">vue考点 —— MVVM</a></em></li><li><em><a href="https://blog.csdn.net/u012551928/article/details/99545791" target="_blank" rel="noopener">MVVM模型</a></em></li><li><em><a href="https://blog.csdn.net/shenwansan_gz/article/details/82284957" target="_blank" rel="noopener">什么是耦合、解耦</a></em></li></ul>]]></content>
    
    
    <categories>
      
      <category>前端开发</category>
      
    </categories>
    
    
    <tags>
      
      <tag>知识点</tag>
      
      <tag>Vue.js</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>拥抱VS Code，抛弃Atom</title>
    <link href="/2020/03/20/vscode/"/>
    <url>/2020/03/20/vscode/</url>
    
    <content type="html"><![CDATA[<blockquote><p>没捣鼓过几个代码编辑器，都不好意思说自己写过代码。</p></blockquote><p>留学的时候，因为开源和颜值，爱上了Atom，期间不管它多少次龟速加载我都毫无怨言，teletype好用，暗黑主题真香。<a id="more"></a> 至于Sublime Text，因为当初觉得界面太丑，用了一次就放弃了。</p><p>可是，前几天看到VS Code、Sublime和Atom的趋势图，VS Code的势头在这两年增长很迅猛。经过两年的更新之后，VS Code的功能已经非常健全，加上速度快不卡顿，再加上还能下载Atom的主题插件，于是我就叛逃到VS Code，卸载了Atom 🙈。</p><p>经过一番折腾，记录下目前觉得实用的插件：</p><h2 id="One-Dark-Pro主题"><a href="#One-Dark-Pro主题" class="headerlink" title="One Dark Pro主题"></a>One Dark Pro主题</h2><p><img src="/img/one_dark_pro.jpg" srcset="/img/loading.gif" alt="主题"></p><p>Atom里我最爱的主题，留学期间的作业都是依靠这简洁而又不做作的主题，给我了无数次爬起来修复bug的力量。暗黑主题，配色很舒服，我个人非常喜欢。</p><p>One Dark Pro这个主题的配色，相比原版要稍微鲜艳一些，看了一下配置文件里的颜色代码一致，但呈现出来的效果却有一些差别。自己捣鼓了几版配色觉得还是不太满意，暂且先用默认的了。部分类别配色的设置红色偏多，稍稍做了一些修改，显得整体的红配绿不那么突兀。</p><h2 id="Color-Highlight"><a href="#Color-Highlight" class="headerlink" title="Color Highlight"></a>Color Highlight</h2><p>这个插件可以把颜色代码显示出对应的颜色，不需要依靠页面预览才能看到效果，调试CSS配色的时候更加方便，节省时间。</p><h2 id="Live-Server"><a href="#Live-Server" class="headerlink" title="Live Server"></a>Live Server</h2><img src="/img/live.jpg" srcset="/img/loading.gif" width="30%"><p>如果是前端开发，这个插件就很有用了，可以在浏览器实时显示HTML页面。最近在学习Vue，简单的例子都可以在网页里localhost实时预览，不要太方便。</p><h2 id="Vetur"><a href="#Vetur" class="headerlink" title="Vetur"></a>Vetur</h2><p>如果学习Vue，这个插件就是必备了。另外还需要一些其他的配置，后面Vue学习的部分再来细说。</p><p>另外还有代码格式美化、minimap（自带）、terminal（自带）都是编辑器里很好的助手。必需的插件配置好之后，就可以愉快的coding了。另外，VS Code也支持Python相关的环境配置，比如Jupyter Notebook之类的，我暂时还没尝试。</p><p>初步体验下来，VS Code确实像You大说的一样，真香。</p>]]></content>
    
    
    <categories>
      
      <category>前端开发</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2020年的一些计划</title>
    <link href="/2020/01/08/2020%E5%B9%B4%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%A1%E5%88%92/"/>
    <url>/2020/01/08/2020%E5%B9%B4%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%A1%E5%88%92/</url>
    
    <content type="html"><![CDATA[<p>经过一天的时间搭建Hexo，我的个人博客地址有个了雏形，目前还在找背景图片的阶段，再过几天才能整成想要的样子。</p><p>不得不说，Hexo这类工具真的蛮好用，虽然前期花时间部署比较费劲，但是呈现的效果还是非常不错的，再加上自己可以在原有主题的基础上不断折腾，也是乐趣所在。</p><a id="more"></a><p>第一篇博客主要想把2020年我的计划写下来，经常翻看，保持计划的进度。</p><h2 id="2020年计划"><a href="#2020年计划" class="headerlink" title="2020年计划"></a>2020年计划</h2><h3 id="List"><a href="#List" class="headerlink" title="List"></a>List</h3><p>2020年的计划主要是四个方面：</p><ol><li>搭建个人技术博客 （进行中）</li><li>完成一个数据可视化网站项目</li><li>完成一个微信小程序项目</li><li>微信号/百家号</li></ol><p>希望能在今年把这四件事情按顺序一一搭建起来，即使无法做到完成，也希望能开始行动起来，先找到idea，再把整体思路和框架梳理出来。</p><h3 id="关于个人技术博客"><a href="#关于个人技术博客" class="headerlink" title="关于个人技术博客"></a>关于个人技术博客</h3><p>这部分一直想做，但是没腾出时间来好好研究。最开始还是以WordPress来研究，但由于当时觉得部署麻烦，就没继续。后来做了前端的一些项目之后，生出了自己开发博客网站的想法，无意中在知乎上看到了现在已经如此普遍的Hexo、Hugo等等工具，茅塞顿开。这正是我想要的么！</p><p>那为什么没选Hugo？由于Hexo是基于JavaScript的，Hugo是基于Go语言的，前者对我来说更加熟悉，如果想要在原有基础上折腾，也有很多可以发挥的空间，于是就开开心心地花了一天时间部署到了GitHub Page上。基础工作就算完成了。</p><p>第一版的大概长这样：</p><p><img src="/img/3.jpg" srcset="/img/loading.gif" alt="界面"></p><p>熟悉的 “Hello World”。</p><p>接下来就是确定一下更新的计划了。博客基本根据个人的学习情况和前端开发项目的进展情况来更新，知识的总结、遇到的问题以及其他的感悟放到这上面，作为记录。好记性不如烂笔头。</p><h3 id="关于数据可视化网站项目"><a href="#关于数据可视化网站项目" class="headerlink" title="关于数据可视化网站项目"></a>关于数据可视化网站项目</h3><p>元旦的时候，我原本想把之前写的一个爬虫程序抓到的数据作为这个项目的数据源，不过因为爬虫过程还不完善，而且有些地方仍然需要手动干预，所以关于这个项目的构想就暂时搁置了。</p><p>仔细想想，抛开爬虫实时抓取的需求，仅仅把过往累积的数据拿出来做展示也未尝不可。只不过这样一来，没有办法与爬虫程序整合，只能依靠本地抓取到的数据进行可视化，交互性和功能性会差很多。</p><p>春节期间，再好好考虑一下这个项目。</p><h3 id="关于微信小程序项目"><a href="#关于微信小程序项目" class="headerlink" title="关于微信小程序项目"></a>关于微信小程序项目</h3><p>这个项目需要整体学习小程序开发的语言，目前面临几个问题：第一，开发什么，目前还没有认真思考过，没有清晰的idea；第二，其他的项目在前，这个项目可能要往后面排了，现在时间精力都没办法让我好好想关于这个项目的东西。</p><p>所以，Flag就先立在这吧，回头再来拔。。</p><h3 id="微信号-百家号"><a href="#微信号-百家号" class="headerlink" title="微信号/百家号"></a>微信号/百家号</h3><p>自媒体这部分其实开始了很长时间，但是没能坚持下来，断断续续更新，还没得原创头衔，稍显动力不足。</p><p>春节期间的计划是，拿另一个身份重新注册一个公众号，把百家号上发过的文章拿到公众号的平台上重新发一遍。</p><p>其次，争取恢复百家号的日常更新，考虑到自己犯懒，先定在每周末更新一到两篇。</p><p>每年都是Flag自豪的立起来，年终的时候大部分倒下。可能这就是三三同学生活的常态吧。可三三同学也不应该当一条咸鱼，还是要奋力折腾啊！</p><p><strong>がんばって！</strong></p>]]></content>
    
    
    <categories>
      
      <category>计划</category>
      
    </categories>
    
    
    <tags>
      
      <tag>个人</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
